<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"aunean-ls.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="第一章、爬虫基础1.1 HTTP 基本原理1.1.1 URI 和 URL URI 的全称为 Uniform Resource Identifier ，统一资源标志符  URL 称为 Universal Resource Locator，统一资源定位符  URL 是 URI 的子集，也就是说每个 URL 都是 URI ，但不是每个 URI 都是 URL。   1.1.2 超文本 超文本，其英文名称叫">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://aunean-ls.github.io/2021/04/11/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="第一章、爬虫基础1.1 HTTP 基本原理1.1.1 URI 和 URL URI 的全称为 Uniform Resource Identifier ，统一资源标志符  URL 称为 Universal Resource Locator，统一资源定位符  URL 是 URI 的子集，也就是说每个 URL 都是 URI ，但不是每个 URI 都是 URL。   1.1.2 超文本 超文本，其英文名称叫">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201116210501159.png">
<meta property="og:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201116210517596.png">
<meta property="og:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201124104319661.png">
<meta property="og:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201124105453279.png">
<meta property="og:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201124143721294.png">
<meta property="og:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201124155850837.png">
<meta property="article:published_time" content="2021-04-11T08:55:49.081Z">
<meta property="article:modified_time" content="2020-12-25T13:09:34.000Z">
<meta property="article:author" content="Aunean">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="c:/Users/Aunean/AppData/Roaming/Typora/typora-user-images/image-20201116210501159.png">

<link rel="canonical" href="https://aunean-ls.github.io/2021/04/11/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://aunean-ls.github.io/2021/04/11/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Aunean">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-11 16:55:49" itemprop="dateCreated datePublished" datetime="2021-04-11T16:55:49+08:00">2021-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-25 21:09:34" itemprop="dateModified" datetime="2020-12-25T21:09:34+08:00">2020-12-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="第一章、爬虫基础"><a href="#第一章、爬虫基础" class="headerlink" title="第一章、爬虫基础"></a>第一章、爬虫基础</h1><h2 id="1-1-HTTP-基本原理"><a href="#1-1-HTTP-基本原理" class="headerlink" title="1.1 HTTP 基本原理"></a>1.1 HTTP 基本原理</h2><h3 id="1-1-1-URI-和-URL"><a href="#1-1-1-URI-和-URL" class="headerlink" title="1.1.1 URI 和 URL"></a>1.1.1 URI 和 URL</h3><ul>
<li><p>URI 的全称为 Uniform Resource Identifier ，统一资源标志符</p>
</li>
<li><p>URL 称为 Universal Resource Locator，统一资源定位符</p>
</li>
<li><p>URL 是 URI 的子集，也就是说每个 URL 都是 URI ，但不是每个 URI 都是 URL。</p>
</li>
</ul>
<h3 id="1-1-2-超文本"><a href="#1-1-2-超文本" class="headerlink" title="1.1.2 超文本"></a>1.1.2 超文本</h3><ul>
<li>超文本，其英文名称叫作 hypertext ，我们在浏览器里看到的网页就是超文本解析而成的， 网页源代码是一系列系列 HTML 代码，而网页的源代码 HTML 就可以称作超文本。</li>
</ul>
<h3 id="1-1-3-HTTP-和-HTTPS"><a href="#1-1-3-HTTP-和-HTTPS" class="headerlink" title="1.1.3 HTTP 和 HTTPS"></a>1.1.3 HTTP 和 HTTPS</h3><ul>
<li>HTTP 全称是 Hyper Text Transfer Protocol ，中文 叫作超文本传输协议 HTTP 协议是用于从网络传输超文本数据到本地浏览器的传送协议，它能保证高效而准确地传送超文本文档。</li>
<li>HTTPS 的全称是 Hyper Text Transfer Protocol over Secure Socket Layer ，是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版， HTTP 下加入 SSL  层，简称为 HTTPS。</li>
</ul>
<h3 id="1-1-4-请求"><a href="#1-1-4-请求" class="headerlink" title="1.1.4 请求"></a>1.1.4 请求</h3><ul>
<li>请求，由客户端向服务端发出，可以分为 部分内容：请求方法 (Request Method)、请求的网址 (Request URL ）、请求头 (Request Headers)、请求体 (Request Body)。</li>
</ul>
<ol>
<li>请求方法<ul>
<li>常见的方法有两种：GET 和 POST。</li>
<li>GET 和 POST 请求方法有如下区别<ul>
<li>GET 请求中的参数包含在 URL 里面，数据可以在 URL 中看到，而 POST 请求的 URL 会包含这些数据，数据都是通过表单形式传输的，会包含在请求体中.</li>
<li>GET 请求提交的数据最多只有 1024 字节，而 POST 方式没有限制。</li>
</ul>
</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>GET</td>
<td>请求页面，并返回页面内容</td>
</tr>
<tr>
<td>HEAD</td>
<td>类似于 GET 请求， 只不过返回的响应中没有具体的内容，用于获取报头</td>
</tr>
<tr>
<td>POST</td>
<td>大多用于提交表单或上传文件，数据包含在请求体中</td>
</tr>
<tr>
<td>PUT</td>
<td>从客户端向服务器传送的数据取代指定文梢中的内容</td>
</tr>
<tr>
<td>DELETE</td>
<td>请求服务器删除指定的页面</td>
</tr>
<tr>
<td>CONNECT</td>
<td>把服务器当作跳板，让服务器代替客户端防问其他网页</td>
</tr>
<tr>
<td>OPTIONS</td>
<td>允许客户端查看服务器的性能</td>
</tr>
<tr>
<td>TRACE</td>
<td>囚显服务器收到的请求，主要用于测试或诊断</td>
</tr>
</tbody></table>
<ol start="2">
<li>请求的网址</li>
</ol>
<ul>
<li>请求的网址，即统 资惊定位符 URL ，它可以唯一确定我们想请求的资源。</li>
</ul>
<ol start="3">
<li>请求头</li>
</ol>
<ul>
<li><p> Host ：用于指定请求资源的主机 IP 和端口号，其内容为请求 URL 的原始服务器或网关的位置，从 HTTP 1.1版本开始，请求必须包含此内容。</p>
</li>
<li><p>Cookie ：也常用复数形式 Cookies ，这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。它的主要功能是维持当前访问会话 例如，我们输入用户名和密码成功登录某个网站后，服务器会用会话保存登录状态信息，后面我们每次刷新或请求该站点的其他页面时，会发现都是登录状态，这就是 Cookies 的功 Cookies 里有信息标识了我们所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上 Cookies 并将其发送给服务器，服务器通过 Cookies 识别出是我们自己，并且查出当前状态是登录状态，所以返回结果就是登录之后才能看到的网页内容。</p>
</li>
<li><p>Referer ：此内容用来标识这个请求是从哪个页面发过来的，服务器可以拿到这 信息并做相应的处理，如做来源统计、防盗链处理等</p>
</li>
<li><p>User-Agent ：简称 UA ，它是一个特殊的字符串头，可以使服务器识别客户使用的操作系统及版本 浏览器及版本等信息 在做爬虫时加上此信息，可以伪装为浏览器；如果不加，很可能会被识别州为爬虫</p>
</li>
</ul>
<ol start="4">
<li>请求体</li>
</ol>
<ul>
<li>请求体一般承载的内容是 POST 请求中的表单数据，而对于 GET 请求，请求体则为空。</li>
</ul>
<h3 id="1-1-5-响应"><a href="#1-1-5-响应" class="headerlink" title="1.1.5 响应"></a>1.1.5 响应</h3><ul>
<li>响应，由服务端返回给客户端，可以分为 部分：响应状态码（ Response Status Code ）、响应头( Response Headers ）和响应体（ Response Body）</li>
</ul>
<ol>
<li>响应状态码</li>
</ol>
<p><img src="C:\Users\Aunean\AppData\Roaming\Typora\typora-user-images\image-20201116210501159.png" alt="image-20201116210501159"></p>
<p><img src="C:\Users\Aunean\AppData\Roaming\Typora\typora-user-images\image-20201116210517596.png" alt="image-20201116210517596"></p>
<h2 id="1-2-爬虫的基本原理"><a href="#1-2-爬虫的基本原理" class="headerlink" title="1.2 爬虫的基本原理"></a>1.2 爬虫的基本原理</h2><p>我们可以把互联网比作一张大网，而爬虫（即网络爬虫）便是在网上爬行的蜘蛛。把网的节点比作一个个网页，爬虫爬到这就相当于访问了该页面，获取了其信息。可以把节点间的连线比作网页与网页之间的链接关系，这样蜘蛛通过一个节点后，可以顺着节点连线继续爬行到达下一个节点，即通个网页继续获取后续的网页，这样整个网的节点便可以被蜘蛛全部爬行到，网站的数据就可以被抓取下来了。</p>
<p>###1.2.1 爬虫概述</p>
<p>简单来说，爬虫就是获取网页并提取和保存信息的自动 程序，下面概要介绍一下</p>
<ol>
<li>获取网页<ul>
<li>爬虫首先要做的工作就是获取网页，这里就是获取网页的源代码 源代码里包含了网页的部分有用信息 ，所以只要把源代码获取下来，就可以从中提取想要的信息了。</li>
</ul>
</li>
<li>提取信息<ul>
<li>获取网页源代码后，接下来就是分析网页源代码，从中提取我们想要的数据。</li>
</ul>
</li>
<li>保存数据<ul>
<li>可以简单保存为 TXT 文本或 JSON 文本，也可以保存到数据库，如 MySQL MongoDB等。</li>
</ul>
</li>
<li>自动化程序<ul>
<li>说到自动化程序，意思是说爬虫可以代替人来完成这些操作。首先，我们手工当然可以提取这些信息，但是当量特别大或者想快速获取大量数据的话，肯定还是要借助程序。</li>
</ul>
</li>
</ol>
<h3 id="1-2-2-能抓取怎样的数据"><a href="#1-2-2-能抓取怎样的数据" class="headerlink" title="1.2.2 能抓取怎样的数据"></a>1.2.2 能抓取怎样的数据</h3><ol>
<li>最常见的便是常规网页，它们对应着 HTML 码，而最常抓取的便是 HTML 源代码。</li>
<li>JSON 字符串（其中 PI 接口大多采用这样的形式），这种格式的数据方便传输和解析，它们同样可以抓取，而且数据提取更加方便。</li>
<li>各种二进制数据，如图片 、视频和音频等 利用爬虫，我们可以将这些二进制数据抓取下来，然后保存成对应的文件名。</li>
</ol>
<h3 id="1-2-3-JavaScript-渲染页面"><a href="#1-2-3-JavaScript-渲染页面" class="headerlink" title="1.2.3 JavaScript 渲染页面"></a>1.2.3 JavaScript 渲染页面</h3><ul>
<li>有时候，在用 urllib 或 requests 抓取网页时，可以看到的源代码实际和浏览器中看到的不一样。</li>
<li>这是 个非常常见的问题 现在网页越来越多地采用 Ajax 、前端模块化工具来构建，整个网页可能都是由 JavaScript 渲染出来的，也就是说原始的 HTML 代码就是一个空壳。</li>
<li>对于这种，我们可以使用 Selenium、Splash 这样的库来实现模拟 JavaScript 渲染。</li>
<li>其次可以通过post请求。</li>
</ul>
<h1 id="第二章、基本库的使用"><a href="#第二章、基本库的使用" class="headerlink" title="第二章、基本库的使用"></a>第二章、基本库的使用</h1><h2 id="2-1-使用-urllib"><a href="#2-1-使用-urllib" class="headerlink" title="2.1 使用 urllib"></a>2.1 使用 urllib</h2><blockquote>
<p>首先，了解一下 urllib 库，python 内置的 HTTP 请求库，不需要额外的安装。</p>
<p>包含四个模块：</p>
<ul>
<li>request：最基本的 HTTP 请求模块，用来模拟发送请求。</li>
<li>error：异常处理模块，如果出现请求错误，可以捕获这些异常，然后进行重试或其他操作以保证程序不会意外终止。</li>
<li>parse：工具模块，提供了许多 URL 处理方法，比如拆分、解析、合并等。</li>
<li>robotparser ：主要是用来识别网站的 robots.txt 文件，然后判断哪些网站可以爬，哪些网站不可以爬，用的很少。</li>
</ul>
</blockquote>
<h3 id="2-1-1-发送请求"><a href="#2-1-1-发送请求" class="headerlink" title="2.1.1 发送请求"></a>2.1.1 发送请求</h3><ol>
<li><strong>urlopen()</strong></li>
</ol>
<p>urllib.request 模块提供了最基本的构造 HTTP 求的方法， 利用它可以模拟浏览器的一个请求发起过程， 同时它还带有处理授权验证（authenticaton）、重定向（ redirection ）、浏览器 Cookies 及其他内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里定义 response 变量接返回的 HTML</span></span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.python.org&#x27;</span>)</span><br><span class="line"><span class="comment"># read() 读取为二进制的数据，再使用 decode() 方法把它转为字符串</span></span><br><span class="line"><span class="comment"># 并设置字符编码为 utf-8 ，这里要注意，有些网页编码可能是 gb2312 或其他。</span></span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><p>下面我们看下 urlopen() 函数的 API：</p>
</li>
<li><p>urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None ) </p>
</li>
<li><p>data 参数：</p>
<p>data 参数是可选的。如果传递了这个参数，则它的请求方式就不再是 GET 方式，而POST 方式。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">data = <span class="built_in">bytes</span>(urllib.parse.urlencode(&#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;hello&#x27;</span>&#125;), encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=data)</span><br><span class="line"><span class="built_in">print</span>(response.read())</span><br></pre></td></tr></table></figure>

<ul>
<li><p>timeout 参数：</p>
<p>timeout 参数用于设置超时时间，单位为秒，意思就是如果请求超 了设置的这个时间， 还没有得到响应，就会抛出异常。如果不指定该参数，就会使用全局默认时间。</p>
<p>通过设置这个超时时间来控制一个网页如果长时间未 应，就跳过它的抓取。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, timeout=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># 可以用 isinstance() 方法来判断它的类型，作出更详细的异常判断</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(e.reason, socket.timeout):</span><br><span class="line">    	<span class="built_in">print</span>(<span class="string">&#x27;TIME OUT&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>其他参数：</p>
<p>除了 data 参数和 timeout 参数外，还有 context 参数，它必须是 ssl.SSLContext 类型，用来指定SSL 设置。</p>
<p>此外，cafile 和 capath 这两个参数分别指定 CA 证书和它的路径，这个在请求 HTTPS 链接时会有用。</p>
<p>cadefault 参数现在已经弃用了，其默认值为 False。</p>
<p><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.request.html">官方文档</a></p>
</li>
</ul>
<ol start="2">
<li><strong>Request</strong></li>
</ol>
<p>利用 urlopen() 方法可以实现最基本请求的发起，但这几个简单的参数并不足以构建个完整的请求 如果请求中需要加入 Headers 等信息，就可以利用更强大的 Request 类来构建。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">request = urllib.request.Request(<span class="string">&#x27;https://python.org&#x27;</span>, headers=headers)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><p>下面我们看下 Request 的构造方法</p>
<ul>
<li>class urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)</li>
</ul>
</li>
<li><p>第一个参数 url 用于请求 URL 这是必传参数，其他都是可选参数。</p>
</li>
<li><p>第二个参数 data 如果要传，必须传 bytes （字节流）类型的 如果它是字典，可以先用urllib.parse 模块里的 urlencode() 编码。</p>
</li>
<li><p>第 个参数 headers 是一个字典，它就是请求头，我们可以在构造请求时通过 headers 参数直接构造，也可以通过调用请求实例的 add_header() 方法添加。</p>
</li>
<li><p>第四个参数 origin_req_host 指的是请求方的 host 名称或者 IP 地址。</p>
</li>
<li><p>第五个参数 unverifiable 表示这个请求是否是无法验证的，默认是 False ，意思就是说用户没有足够权限来选择接收这个请求的结果。</p>
</li>
<li><p>第六个参数 method 一个字符串 ，用来指示请求使用的方法，比如 GET POST PUT 等。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/post&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.193 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;httpbin.org&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">dict</span> = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Germey&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data = <span class="built_in">bytes</span>(urllib.parse.urlencode(<span class="built_in">dict</span>), encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">req = urllib.request.Request(url=url, data=data, headers=headers, method=<span class="string">&#x27;POST&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(req)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>



<ol start="3">
<li><strong>高级用法</strong></li>
</ol>
<p>那对于一些更高级的操作（比如 Cookies 处理、代理设置等），该如何操作？</p>
<p>接下来，就需要更强大的工具 Handler 登场了。简而言之，我们可以把它理解为各种处理器，有专门处理登录验证的，有处理 Cookies 的，有处理代理设置的 利用它们，我们几乎可以做到 HTTP 请求中所有的事情。</p>
<p>urllib.request 模块里的 BaseHandler 类，它是所有其他 Handler 的父类，它提供了最基本的方法，例如 default_open()、protocol_request() 等。</p>
<p>接下来，就有各种 Ha dler 子类继承这个 BaseHandler 类，举例如下：</p>
<ul>
<li>HTTPDefaultErrorHandler：处理 HTTP 响应错误，错误都会抛出 HTTPError 类型的异常。</li>
<li>HTTPRedirectHandler：用于处理重定向。</li>
<li>HTTPCookieProcessor：用于处理 Cookies。</li>
<li>ProxyHandler：用于设置代理，默认代理为空。</li>
<li>HTTPPasswordMgr：用于管理密码，它维护了用户名和密码的表。</li>
<li>HTTPBasicAuthHandler 用于管理认证，如果一个链接打开时需要认证，那么可以用它来解决认证问题。</li>
</ul>
<p><a href="'https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler'">详见官方文档</a></p>
<ul>
<li>验证登陆，借助 HTTPBasicAuthHandler 可以完成</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPPasswordMgrWithDefaultRealm, HTTPBasicAuthHandler, build_opener</span><br><span class="line"><span class="comment"># 对于异常的处理</span></span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"></span><br><span class="line">username = <span class="string">&#x27;username&#x27;</span></span><br><span class="line">password = <span class="string">&#x27;password&#x27;</span></span><br><span class="line">url = <span class="string">&#x27;https://www.zhihu.com/hot&#x27;</span></span><br><span class="line">p = HTTPPasswordMgrWithDefaultRealm()</span><br><span class="line">p.add_password(<span class="literal">None</span>, url, username, password)</span><br><span class="line">auth_handler = HTTPBasicAuthHandler(p)</span><br><span class="line">opener = build_opener(auth_handler)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    result = opener.<span class="built_in">open</span>(url)</span><br><span class="line">    html = result.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(html)</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>

<ul>
<li>代理</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler, build_opener</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里的代理IP不能使用，网上的免费代理IP大多都不能使用。</span></span><br><span class="line">proxy_handler = ProxyHandler(&#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:9743&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://127.0.0.1:9743&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line">opener = build_opener(proxy_handler)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = opener.<span class="built_in">open</span>(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>

<ul>
<li>Cookies</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取网站的Cookies</span></span><br><span class="line"><span class="keyword">import</span> http.cookiejar</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">cookie = http.cookiejar.CookieJar()</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.<span class="built_in">open</span>(<span class="string">&#x27;https://www.zhihu.com/hot&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</span><br><span class="line">    <span class="built_in">print</span>(item.name+<span class="string">&#x27;=&#x27;</span>+item.value)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> http.cookiejar</span><br><span class="line">url = <span class="string">&#x27;https://www.zhihu.com/hot&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Linux; Android 8.0.0; Pixel 2 XL Build/OPD1.170816.004) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Mobile Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">cookie = http.cookiejar.CookieJar()</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">request = urllib.request.Request(url, headers=headers, method=<span class="string">&#x27;GET&#x27;</span>)</span><br><span class="line">r = opener.<span class="built_in">open</span>(request)</span><br><span class="line">html = r.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(html)</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2-处理异常"><a href="#2-1-2-处理异常" class="headerlink" title="2.1.2 处理异常"></a>2.1.2 处理异常</h3><p>urllib 的 error 模块定义了由 request 模块产生的异常 如果出现了问题，request 模块便会抛出 error 模块中定义的异常。</p>
<ol>
<li>URLError</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">&#x27;https://cuiqingcai.com/index.htm&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br><span class="line"><span class="comment"># 打开一个不存在的页面照理来说应该会报错，但是这时我们捕获了 URLError 这个异常。输出：Not Found。通过如上操作，我们就可以避免程序异常终止，同时异常得到了有效处理。</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>HTTPError</li>
</ol>
<p>URL Error 的子类，专门用来处理 HTTP 请求错误，比如认证请求失败等。</p>
<p>它有如下三个属性：</p>
<ul>
<li>code：返回 HTTP 状态码，比如 404 表示网页不存在，500 表示服务器内部错误等。</li>
<li>reason：同父类一样，用于返回错误的原因。</li>
<li>headers：返回请求头。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">&#x27;https://cuiqingcai.com/index.htm&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason, e.code, e.headers, sep=<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Request Successfully&#x27;</span>)</span><br><span class="line"><span class="comment"># 因为 URLError 是 HTTPError 的父类，所以可以先选择捕获子类的错误，再去捕获父类的错误。</span></span><br></pre></td></tr></table></figure>

<h3 id="2-1-3-解析链接"><a href="#2-1-3-解析链接" class="headerlink" title="2.1.3 解析链接"></a>2.1.3 解析链接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># urlparse() 该方法可以实现 URL 的识别和分段</span></span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line">result = urlparse(<span class="string">&#x27;http://www.baidu.com/index.html;user?id=5#comment&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result), result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># scheme=&#x27;http&#x27;				协议</span></span><br><span class="line"><span class="comment"># netloc=&#x27;www.baidu.com&#x27;	域名</span></span><br><span class="line"><span class="comment"># path=&#x27;/index.html&#x27;		访问路径</span></span><br><span class="line"><span class="comment"># params=&#x27;user&#x27;				参数</span></span><br><span class="line"><span class="comment"># query=&#x27;id=5&#x27;				查询条件</span></span><br><span class="line"><span class="comment"># fragment=&#x27;comment&#x27;		锚点</span></span><br><span class="line"><span class="comment"># 标准的链接格式</span></span><br><span class="line"><span class="comment"># scheme://netloc/path;params?query#fragment</span></span><br></pre></td></tr></table></figure>



<h2 id="2-2-使用-requests"><a href="#2-2-使用-requests" class="headerlink" title="2.2 使用 requests"></a>2.2 使用 requests</h2><p>###2.2.1 基本用法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r))</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.text))</span><br><span class="line"><span class="built_in">print</span>(r.content.decode())</span><br><span class="line"><span class="built_in">print</span>(r.cookies)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">对于 GET 请求，如果要附加额外的信息，一般怎样添加呢？比如现在想添加两个参数，</span></span><br><span class="line"><span class="string">其中 name是germey, age是22 要构造这个请求链接</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;age&#x27;</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">url = requests.get(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, headers=headers, data=data)</span><br><span class="line"><span class="built_in">print</span>(url.text)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(url.text))</span><br><span class="line"><span class="built_in">print</span>(url.json())</span><br></pre></td></tr></table></figure>

<ul>
<li>抓取网页、添加headers</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">上面的请求链接返回的是 JSON 形式的字符串，那么如果请求普通的网页，则肯定能获得相应的</span></span><br><span class="line"><span class="string">内容了 下面以“知乎”→“发现”页面为例</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 在这里，如果不设置U-A，就不能正常请求</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>, headers=headers).text</span><br><span class="line">pattern = <span class="string">&#x27;view-id=&quot;5799&quot;&gt;(.*?)&lt;/a&gt;&#x27;</span></span><br><span class="line">titles = re.findall(pattern, r, re.S)</span><br><span class="line"><span class="comment"># print(titles)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> titles:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<ul>
<li> 抓取二进制数据</li>
</ul>
<p>图片、音频、视频这些文件本质上都是由二进制码组成的，由于有特定的保存格式和对应的解析方式， 我们才可以看到这些形形色色的多媒体。所以，想要抓取它们，就要拿到它们的二进制码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">url = requests.get(<span class="string">&#x27;https://github.com/favicon.ico&#x27;</span>)</span><br><span class="line"><span class="comment"># print(url.text)  # 打印时转化为 str 类型，图片直接转化为字符串，会出现乱码</span></span><br><span class="line"><span class="comment"># print(url.content)  # 前带有一个b</span></span><br><span class="line"><span class="comment"># wb 以二进制写入打开一个文件。如果该文件已存在，则将其覆盖。</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="comment"># content 是将网页数据以二进制输出</span></span><br><span class="line">    f.write(url.content)</span><br></pre></td></tr></table></figure>

<ul>
<li>post请求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">22</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=data)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">2．POST方式</span></span><br><span class="line"><span class="string">网页的访问方式除了GET方式以外，还有POST方式。</span></span><br><span class="line"><span class="string">有一些网页，使用GET和POST方式访问同样的网址，得到的结果是不一样的。</span></span><br><span class="line"><span class="string">还有另外一些网页，只能使用POST方式访问，如果使用GET方式访问，网站会直接返回错误信息。</span></span><br><span class="line"><span class="string">此时就需要使用requests的post()方法来获取源代码。</span></span><br><span class="line"><span class="string">post()方法的格式如下：</span></span><br><span class="line"><span class="string">import requests</span></span><br><span class="line"><span class="string">data = &#123;&#x27;key1&#x27;: &#x27;value1&#x27;,&#x27;key2&#x27;: &#x27;value2&#x27;&#125;</span></span><br><span class="line"><span class="string">html_formdata = requests.post(&#x27;网址&#x27;, data=data).content.decode() </span></span><br><span class="line"><span class="string">其中，data这个字典的内容和项数需要根据实际情况修改，Key和Value在不同的网站是不一样的。</span></span><br><span class="line"><span class="string">而做爬虫，构造这个字典是任务之一。</span></span><br><span class="line"><span class="string">还有一些网址，提交的内容需要是JSON格式的，因此post()方法的参数需要进行一些修改：</span></span><br><span class="line"><span class="string">html_json = requests.post(&#x27;网址&#x27;, json=data).content.decode() </span></span><br><span class="line"><span class="string">#使用JSON提交数据。这样写代码，requests可以自动将字典转换为JSON字符串。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.post方式的使用</span></span><br><span class="line"><span class="comment"># 通过formdata提交数据</span></span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;ouni&#x27;</span>, <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;123456&#x27;</span>&#125;</span><br><span class="line">html_formdata = requests.post(<span class="string">&#x27;http://exercise.kingname.info/exercise_requests_post&#x27;</span>, data=data).content.decode()</span><br><span class="line"><span class="built_in">print</span>(html_formdata)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过JSON提交数据</span></span><br><span class="line">html_formdata = requests.post(<span class="string">&#x27;http://exercise.kingname.info/exercise_requests_post&#x27;</span>, json=data).content.decode()</span><br><span class="line"><span class="built_in">print</span>(html_formdata)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-高级用法"><a href="#2-2-2-高级用法" class="headerlink" title="2.2.2 高级用法"></a>2.2.2 高级用法</h3><ol>
<li>文件上传</li>
</ol>
<p>requests 可以 拟提交一些数据，假如有的网站需要上传文件，我们也可以用它来实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># favicon.ico 为文件名，此外还需注意路径。</span></span><br><span class="line">files = &#123;<span class="string">&#x27;file&#x27;</span>: <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>)&#125;</span><br><span class="line">r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, files=files)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Cookies</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.cookies)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">    <span class="built_in">print</span>(key + <span class="string">&#x27;=&#x27;</span> + value)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>会话维持</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通方法</span></span><br><span class="line"><span class="comment"># requests.get(&quot;http://httpbin.org/cookies/set/number/123456789&quot;)</span></span><br><span class="line"><span class="comment"># r = requests.get(&#x27;http://httpbin.org/cookies&#x27;)</span></span><br><span class="line"><span class="comment"># print(r.text)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Session</span></span><br><span class="line">s = requests.Session()</span><br><span class="line">s.get(<span class="string">&quot;http://httpbin.org/cookies/set/number/123456789&quot;</span>)</span><br><span class="line">r = s.get(<span class="string">&#x27;http://httpbin.org/cookies&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>SSL 证书验证</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 verify 参数控制是否检查此证书</span></span><br><span class="line"><span class="keyword">from</span> requests.packages <span class="keyword">import</span> urllib3</span><br><span class="line">urllib3.disable_warnings()</span><br><span class="line">response = requests.get(<span class="string">&#x27;https://www.12306.cn&#x27;</span>, verify=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>代理设置</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">对于某些网站，在测试的时候请求几次，能正常获取内容 但是一旦开始大规模爬取，对于大规模且频繁的请求，网站可能会弹出验证码，或者跳转到登录认证页面，更甚者可能会直接封禁客户端，导致一定时间段内无法访问。为了防止这种情况发生，需要设置代理来解决这个问题，这就需要用到 proxies 参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&quot;使用 HTTP Basic Auth,可以使用类似 http://user:password@host:port 这样的语法来置代理，示例如下：&quot;</span></span><br><span class="line"><span class="comment"># proxies = &#123;</span></span><br><span class="line"><span class="comment">#     &#x27;http&#x27;: &#x27;http://user:password@10.10.1.10:3128&#x27;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"><span class="comment"># response = requests.get(&#x27;https://www.taobao.com&#x27;, proxies=proxies)</span></span><br><span class="line"><span class="comment"># print(response)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># pip install &#x27;requests[socks]&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># &quot;除了基本的 HTTP 代理外， equests 还支持 SOCKS 协议的代理&quot;</span></span><br><span class="line"><span class="comment"># import requests</span></span><br><span class="line"><span class="comment"># proxies = &#123;</span></span><br><span class="line"><span class="comment">#     &#x27;http&#x27;: &#x27;socks5://user:password@host:port&#x27;,</span></span><br><span class="line"><span class="comment">#     &#x27;https&#x27;: &#x27;socks5://user:password@host:port&#x27;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"><span class="comment"># response = requests.get(&#x27;https://www.taobao.com&#x27;, proxies=proxies)</span></span><br><span class="line"><span class="comment"># print(response)</span></span><br></pre></td></tr></table></figure>



<h2 id="2-3-正则表达式"><a href="#2-3-正则表达式" class="headerlink" title="2.3 正则表达式"></a>2.3 正则表达式</h2><p>###2.3.1 常用的匹配规则</p>
<p><img src="C:\Users\Aunean\AppData\Roaming\Typora\typora-user-images\image-20201124104319661.png" alt="image-20201124104319661"></p>
<p>###2.3.2 match()</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">content = <span class="string">&#x27;Hello 123 4567 World_This is a Regex Demo&#x27;</span></span><br><span class="line"><span class="comment"># print(len(content))</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello\s\d\d\d\s\d&#123;4&#125;\s\w&#123;10&#125;&#x27;</span>, content, re.S)</span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"><span class="comment"># print(result.group())</span></span><br><span class="line"><span class="comment"># print(result.span())</span></span><br></pre></td></tr></table></figure>

<ul>
<li>匹配目标</li>
</ul>
<p>刚才我们用 match() 方法可以得到匹配到的字符串内容，但是如果想从字符串中提 一部分内容，该怎么办呢？就像最前面的实例一样，从一段文本中提取出邮件或电话号码等内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1.使用match()方法进行匹配，如果在起始位置匹配成功，则返回Match对象，否则返回None，</span></span><br><span class="line"><span class="string">语法格式：</span></span><br><span class="line"><span class="string">re.match(pattern, string, [flags])</span></span><br><span class="line"><span class="string">pattern：表示模式字符串，由要匹配的正则表达式转换而来</span></span><br><span class="line"><span class="string">string：表示要匹配的字符串</span></span><br><span class="line"><span class="string">flags：可选参数，表示标志位，用于控制匹配方式，如是否区分字母大小写。如下：</span></span><br><span class="line"><span class="string">   标志                       说明</span></span><br><span class="line"><span class="string">A或ASCII         对于\w \W \b \B \D \s \S 只进行ASCII匹配</span></span><br><span class="line"><span class="string">I或IGNORECASE    执行不区分字母大小写的匹配</span></span><br><span class="line"><span class="string">M或MULTILINE     将^和$用于包括整个字符串的开始和结尾的每一行</span></span><br><span class="line"><span class="string">S或DOTALL        使用(.)字符匹配所有字符，包括换行符</span></span><br><span class="line"><span class="string">X或VERBOSE       忽略模式字符串中未转义的空格和注释</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">pattern = <span class="string">r&#x27;mr_\w+&#x27;</span></span><br><span class="line">string = <span class="string">&#x27;MR_SHOP mr_shop&#x27;</span></span><br><span class="line">match = re.match(pattern, string, re.I)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;匹配值的起始位置：&#x27;</span>, match.start())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;匹配值的结束位置：&#x27;</span>, match.end())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;匹配位置的元组：&#x27;</span>, match.span())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;要匹配的字符串：&#x27;</span>, match.string)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;匹配数据：&#x27;</span>, match.group())</span><br><span class="line">string = <span class="string">&#x27;项目名称MR_SHOP mr_shop&#x27;</span></span><br><span class="line">match = re.match(pattern, string, re.I)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello\s(.*?)\s\w&#123;10&#125; (.*?)\s&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># &lt;re.Match object; span=(0, 25), match=&#x27;Hello 123 4567 World_This&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(result.group())  <span class="comment"># Hello 123 4567 World_This</span></span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>))  <span class="comment"># 1234567</span></span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">2</span>))  <span class="comment"># is</span></span><br></pre></td></tr></table></figure>

<ul>
<li>修饰符</li>
</ul>
<p><img src="C:\Users\Aunean\AppData\Roaming\Typora\typora-user-images\image-20201124105453279.png" alt="image-20201124105453279"></p>
<h3 id="2-3-3-search"><a href="#2-3-3-search" class="headerlink" title="2.3.3 search()"></a>2.3.3 search()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">search()方法用于整个字符串中搜索第一个匹配的值，如果匹配成功，则返回Match对象，</span></span><br><span class="line"><span class="string">否则返回None。语法格式如下：</span></span><br><span class="line"><span class="string">re.search(pattern, string, [flags])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">pattern = <span class="string">r&#x27;mr_\w+&#x27;</span></span><br><span class="line">string = <span class="string">&#x27;MR_SHOP mr_shop&#x27;</span></span><br><span class="line">match = re.search(pattern, string, re.I)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line">string = <span class="string">&#x27;项目名称MR_SHOP mr_shop&#x27;</span></span><br><span class="line">match = re.search(pattern, string, re.I)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br></pre></td></tr></table></figure>



<h3 id="2-3-4-findall"><a href="#2-3-4-findall" class="headerlink" title="2.3.4 findall()"></a>2.3.4 findall()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">findall()方法用于在整个字符串中搜索所有符合正则表达式的字符串，并以列表的形式</span></span><br><span class="line"><span class="string">返回。如果匹配成功，则返回包含匹配结构的列表，否则返回空列表。</span></span><br><span class="line"><span class="string">re.findall(pattern, string, [flags])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">pattern = <span class="string">r&#x27;mr_\w+&#x27;</span></span><br><span class="line">string = <span class="string">&#x27;MR_SHOP mr_shop&#x27;</span></span><br><span class="line">match = re.findall(pattern, string, re.I)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line">string = <span class="string">&#x27;项目名称MR_SHOP mr_shop&#x27;</span></span><br><span class="line">match = re.findall(pattern, string)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line"></span><br><span class="line">pattern = <span class="string">r&#x27;([1-9]&#123;1,3&#125;(\.[0-9]&#123;1,3&#125;)&#123;3&#125;)&#x27;</span></span><br><span class="line">str1 = <span class="string">&#x27;127.0.0.1 192.168.1.66&#x27;</span></span><br><span class="line">match = re.findall(pattern, str1)</span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> match:</span><br><span class="line">    <span class="built_in">print</span>(i[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>



<h3 id="2-3-5-sub"><a href="#2-3-5-sub" class="headerlink" title="2.3.5 sub()"></a>2.3.5 sub()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">sub()</span></span><br><span class="line"><span class="string">除了使用正则表达式提取信息外，有时候还需要借助它来修改文本,</span></span><br><span class="line"><span class="string">比如，想要把一串文本中的所有数字都去掉，如果只用字符串的 replace()</span></span><br><span class="line"><span class="string">方法，那就太烦琐了，这时可以借助 sub() 方法</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">content = <span class="string">&#x27;54aKS4yrsoiRS4ixSL2g数字&#x27;</span></span><br><span class="line">content = re.sub(<span class="string">&#x27;\d+|[\u4e00-\u9fa5]&#x27;</span>, <span class="string">&#x27;&#x27;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>





<h1 id="第三章、解析库的使用"><a href="#第三章、解析库的使用" class="headerlink" title="第三章、解析库的使用"></a>第三章、解析库的使用</h1><h2 id="3-1-使用-XPath"><a href="#3-1-使用-XPath" class="headerlink" title="3.1 使用 XPath"></a>3.1 使用 XPath</h2><p>XPath 全称 XML Path Language ，即 XML 路径语言，它是一门在 XML 文档中查找信息的语言。它最初是用来搜寻 XML 文档的，但是它同样适用于 HTML 文档的搜索。</p>
<p><a target="_blank" rel="noopener" href="https://www.w3.org/TR/xpath">官方文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">XPath语句格式</span></span><br><span class="line"><span class="string">         核心思想：写XPath就是写地址。</span></span><br><span class="line"><span class="string">         获取文本：</span></span><br><span class="line"><span class="string">//标签1[@属性1=&quot;属性值1&quot;]/标签2[@属性2=&quot;属性值2&quot;]/..../text()</span></span><br><span class="line"><span class="string">获取属性值：</span></span><br><span class="line"><span class="string">//标签1[@属性1=&quot;属性值1&quot;]/标签2[@属性2=&quot;属性值2&quot;]/..../@属性n</span></span><br><span class="line"><span class="string">其中，[@属性=&quot;属性值&quot;]不是必需的。它的作用是帮助过滤相同的标签。</span></span><br><span class="line"><span class="string">在不需要过滤相同标签的情况下可以省略。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">哪些属性可以省略</span></span><br><span class="line"><span class="string">&lt;ul&gt;标签本身就没有属性，则写XPath的时候，其属性可以省略。</span></span><br><span class="line"><span class="string">标签有属性，但是如果这个标签的所有属性值都相同，则可以省略属性，</span></span><br><span class="line"><span class="string">例如&lt;li class=&quot;info&quot;&gt;，所有的&lt;li&gt;标签都有一个class属性，值都为info，所以属性可以省略。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>==<strong>对于 tboty 标签，实际匹配不到的，在写的时候需要注意</strong>==</p>
<h3 id="3-1-1-XPath-常用使用规则"><a href="#3-1-1-XPath-常用使用规则" class="headerlink" title="3.1.1 XPath 常用使用规则"></a>3.1.1 XPath 常用使用规则</h3><table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>nodename</td>
<td>选取此节点的所有子节点</td>
</tr>
<tr>
<td>/</td>
<td>从当前节点选取直接子节点</td>
</tr>
<tr>
<td>//</td>
<td>从当前节点选取子孙节点</td>
</tr>
<tr>
<td>.</td>
<td>选取当前节点</td>
</tr>
<tr>
<td>..</td>
<td>选取当前节点的父节点</td>
</tr>
<tr>
<td>@</td>
<td>选取属性</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入lxml库</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取text.html文件并转化为元素树对象</span></span><br><span class="line">parse = etree.HTMLParser(encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">tree = etree.parse(<span class="string">&#x27;text.html&#x27;</span>, parse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补充xpath表达式,获取所有书的名称</span></span><br><span class="line"><span class="comment"># ********** Begin ********* #</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;//book/title/text()&#x27;</span>))</span><br><span class="line"><span class="comment"># *********** End ********** #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 补充xpath表达式,获取所有书的价格</span></span><br><span class="line"><span class="comment"># ********** Begin ********* #</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;//book/price/text()&#x27;</span>))</span><br><span class="line"><span class="comment"># *********** End ********** #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 填写代码, 获取价格低于30的书名</span></span><br><span class="line"><span class="comment"># ********** Begin ********* #</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;//book/title[@class=&quot;good&quot;]/text()&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># *********** End ********** #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 相对路径 book 节点选择</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;//book[1]/title/text()&#x27;</span>))</span><br><span class="line"><span class="comment"># 相对路径 title 节点存在 class 属性条件选择</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;//title[@class]/@class&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 同上, 但是使用了轴选择 class 属性值</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;//title[@class]/attribute::class&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 绝对路径常规选择</span></span><br><span class="line"><span class="built_in">print</span>(tree.xpath(<span class="string">&#x27;/html/body/bookstore//book[1]/title/@class&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5获取价格小于30的书名</span></span><br><span class="line">book_name = tree.xpath(<span class="string">&quot;//book[price&lt;30]/title/text()&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(book_name[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6获取价格等于39.95的书</span></span><br><span class="line">book_name = tree.xpath(<span class="string">&quot;//book[price=39.95]/title/text()&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(book_name)</span><br></pre></td></tr></table></figure>

<p>###3.1.2 所有节点</p>
<p>例：html.xpath(‘//*’)</p>
<h3 id="3-1-3-子节点"><a href="#3-1-3-子节点" class="headerlink" title="3.1.3 子节点"></a>3.1.3 子节点</h3><p>例：html.xpath(‘//li/a’)</p>
<h3 id="3-1-4-子孙节点"><a href="#3-1-4-子孙节点" class="headerlink" title="3.1.4 子孙节点"></a>3.1.4 子孙节点</h3><p>例：html.xpath(‘//li//a’)</p>
<h3 id="3-1-5-父节点"><a href="#3-1-5-父节点" class="headerlink" title="3.1.5 父节点"></a>3.1.5 父节点</h3><p>选中 href 属性为 link4.html 节点，然后再获取其父节点，然后再获取其 class 属性，相关代码如下：</p>
<p>例：html.xpath(‘//a[@href=”link4.html”]/../@class’)</p>
<p>同时，也可以通过 parent:: 来获取父节点</p>
<p>html.xpath(‘//a[@href=”link4.html”]/parent::*/@class’)</p>
<h3 id="3-1-6-属性匹配"><a href="#3-1-6-属性匹配" class="headerlink" title="3.1.6 属性匹配"></a>3.1.6 属性匹配</h3><p>要选取 class 为 item-1 的 li节点，可以这样实现：</p>
<p>html.xpath(‘//li[@class=”itme-1”]’)</p>
<h3 id="3-1-7-文本获取"><a href="#3-1-7-文本获取" class="headerlink" title="3.1.7 文本获取"></a>3.1.7 文本获取</h3><p>html.xpath(‘//li[@class=”item-0”]/text()’)</p>
<h3 id="3-1-8属性获取"><a href="#3-1-8属性获取" class="headerlink" title="3.1.8属性获取"></a>3.1.8属性获取</h3><p>获取所有 li 节点下所有 节点的 href 属性</p>
<p>html.xpath(‘//li/a/@href’)</p>
<h3 id="3-1-9-属性多值匹配"><a href="#3-1-9-属性多值匹配" class="headerlink" title="3.1.9 属性多值匹配"></a>3.1.9 属性多值匹配</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&quot;&quot;&quot;&lt;li class=&quot;li li-first&quot;&gt;&lt;a href=&quot;link.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;&quot;&quot;&quot;</span></span><br><span class="line">html = etree.HTML(text)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;这里 HTML 文本中 li 节点的 class 属性有两个值 li li-first，</span></span><br><span class="line"><span class="string">此时如果还想用之前的属性匹配获取，就无法匹配了&#x27;&#x27;&#x27;</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[@class=&quot;li&quot;]/a/text()&#x27;</span>)</span><br><span class="line"><span class="comment"># result = html.xpath(&#x27;//li[@class=&quot;li li-first&quot;]/a/text()&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这时就需要用 contains() 函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;这样通过 contains()方法，第一个参数传人属性名称，第二个参数传人属性值，只要此属性包含</span></span><br><span class="line"><span class="string">所传人的属性值，就可以完成匹配&#x27;&#x27;&#x27;</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[contains(@class, &quot;li&quot;)]/a/text()&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<h3 id="3-1-10-多属性匹配"><a href="#3-1-10-多属性匹配" class="headerlink" title="3.1.10 多属性匹配"></a>3.1.10 多属性匹配</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">多属性匹配</span></span><br><span class="line"><span class="string">我们可能还遇到一种情况，那就是根据多个属性确定一个节点，这时就需要同时匹配多个</span></span><br><span class="line"><span class="string">属性 此时可以使用运算符 and 来连接，</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">text = <span class="string">&#x27;&lt;li class=&quot;li li-first&quot; name=&quot;item&quot;&gt;&lt;a href=&quot;link.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;&#x27;</span></span><br><span class="line">html = etree.HTML(text)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[contains(@class, &quot;li&quot;) and @name=&quot;item&quot;]/a/text()&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<p><strong>运算符及其介绍</strong><img src="C:\Users\Aunean\AppData\Roaming\Typora\typora-user-images\image-20201124143721294.png" alt="image-20201124143721294"></p>
<h3 id="3-1-11-按序选择"><a href="#3-1-11-按序选择" class="headerlink" title="3.1.11 按序选择"></a>3.1.11 按序选择</h3><p> <a href="..........%5Clearning%5Cspider%5Cproject%5C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%5Ctext.html">text.html</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">按序选择</span></span><br><span class="line"><span class="string">有时候，我们在选择的时候某些属性可能同时匹配了多个节点，但是只想要其中的某个节点，如</span></span><br><span class="line"><span class="string">第二个节点或者最后一个节点，</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">html = etree.parse(<span class="string">&#x27;../text.html&#x27;</span>, etree.HTMLParser())</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/a/text()&#x27;</span>)  <span class="comment"># 选取第一个 li 节点</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[last()]/a/text()&#x27;</span>)  <span class="comment"># 最后一个 li 节点</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[position()&lt;4]/a/text()&#x27;</span>)  <span class="comment"># 选取位置小于四的节点</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[last()-2]/a/text()&#x27;</span>)  <span class="comment"># 倒数第三个节点</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<h3 id="3-1-12-节点轴选择"><a href="#3-1-12-节点轴选择" class="headerlink" title="3.1.12 节点轴选择"></a>3.1.12 节点轴选择</h3><p>XPath 提供了很多节点轴选择方法，包括获取子元素 、兄弟元素、父元素、祖先元素等，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">html = etree.parse(<span class="string">&#x27;../text.html&#x27;</span>, etree.HTMLParser())</span><br><span class="line"><span class="comment"># 1.调用 ancestor 轴，获取所有祖先节点。然后是节点的选择器，这里直接使用*，表示匹配所有节点</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/ancestor::*&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 2.改 * 为 div ，这样得到的结果只有div这个祖先节点了</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/ancestor::div&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 3.调用 attribute 轴，获取所有属性值。其后跟的选择器还是＊，这代</span></span><br><span class="line"><span class="comment"># 获取节点的所有属性，返回值就是 li 节点的所有属性值</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/attribute::*&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 4.调用了 child 轴，可以获取所有直接子节点 这里我们又加了限定条件，选</span></span><br><span class="line"><span class="comment"># href 属性为 link1.html 的a节点</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/child::a[@href=&quot;link1.html&quot;]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 5.调用 descendant 轴，可以获取所有子孙节点。这里有添加限定条件获取span节点，所以返回的结果只包含span节点</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/descendant::span&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 6.调用 following 轴，可以获取当前节点之后的所有节点。</span></span><br><span class="line"><span class="comment"># 虽然这里使用*匹配，但又加了索引选择，所以只获取了第二个后续节点</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/following::*[2]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 7.调用 following-sibling 轴，可以获取当前节点之后的所有同级节点。</span></span><br><span class="line"><span class="comment"># 这里我们使用 * 匹配，所以获取了所有后续同级节点。</span></span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[1]/following-sibling::*&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="http://www.w3school.com.cn/xpath/index.asp">更多xpath用法</a></p>
<h2 id="3-2-使用-Beautiful-Soup"><a href="#3-2-使用-Beautiful-Soup" class="headerlink" title="3.2 使用 Beautiful Soup"></a>3.2 使用 Beautiful Soup</h2><h3 id="3-2-1-基本用法"><a href="#3-2-1-基本用法" class="headerlink" title="3.2.1 基本用法"></a>3.2.1 基本用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">基本用法</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt; </span></span><br><span class="line"><span class="string">&lt;body&gt; </span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt; </span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were </span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, </span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and </span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; </span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt; </span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;对于不标准的 HTML 字符串, BeautifulSoup 可以自动更正格式&#x27;</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;调用 prettify()方法 这个方法可以把要解析的字符串以标准的缩进格式输出&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(soup.prettify())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.prettify()))</span><br><span class="line"><span class="built_in">print</span>(soup.title.string)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-节点选择器"><a href="#3-2-2-节点选择器" class="headerlink" title="3.2.2 节点选择器"></a>3.2.2 节点选择器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">节点选择器</span></span><br><span class="line"><span class="string">直接调用节点的名称就可以选择节点元素，再调用 string 属性就可以得到节点内的文本了，这种</span></span><br><span class="line"><span class="string">选择方式速度非常快。如果单个节点结构层次非常清晰，可以选用这种方式来解析</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.title))  <span class="comment"># &lt;class &#x27;bs4.element.Tag&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(soup.title)  <span class="comment"># &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;</span></span><br><span class="line"><span class="comment"># 获取名称。利用 name 属性获取节点的名称</span></span><br><span class="line"><span class="built_in">print</span>(soup.title.name)</span><br><span class="line"><span class="built_in">print</span>(soup.head)</span><br><span class="line"><span class="built_in">print</span>(soup.p)  <span class="comment"># &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;attrs 的返回结果是字典形式，它把选择的节点的所有属性和属性值组合成一个字典&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.attrs)  <span class="comment"># &#123;&#x27;class&#x27;: [&#x27;title&#x27;], &#x27;name&#x27;: &#x27;dromouse&#x27;&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;这里需要注意的是，有的返回结果是字符串，有的返回结果是字符串组成的列表 比如， </span></span><br><span class="line"><span class="string">name属性的值是唯一的，返回的结果就是单个字符串,而对于 class 一个节点元素可能有多个 class 所以</span></span><br><span class="line"><span class="string">返回的是列表&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.attrs[<span class="string">&#x27;name&#x27;</span>])  <span class="comment"># dromouse</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.attrs[<span class="string">&#x27;class&#x27;</span>])  <span class="comment"># [&#x27;title&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取内容。可以利用 string 属性获取节点元素包含的文本内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.title.string)  <span class="comment"># The Dormouse&#x27;s story</span></span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-关联选择"><a href="#3-2-3-关联选择" class="headerlink" title="3.2.3 关联选择"></a>3.2.3 关联选择</h3><ol>
<li>子节点和子孙节点</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">html = <span class="string">&#x27;&#x27;&#x27;&lt;html&gt;</span></span><br><span class="line"><span class="string"> &lt;head&gt;</span></span><br><span class="line"><span class="string">  &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;</span></span><br><span class="line"><span class="string"> &lt;/head&gt;</span></span><br><span class="line"><span class="string"> &lt;body&gt;</span></span><br><span class="line"><span class="string">  &lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">   Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">   &lt;a  href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;</span></span><br><span class="line"><span class="string">    &lt;span&gt;Elsie&lt;/span&gt;</span></span><br><span class="line"><span class="string">   &lt;/a&gt;</span></span><br><span class="line"><span class="string">   &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</span></span><br><span class="line"><span class="string">    and</span></span><br><span class="line"><span class="string">   &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.</span></span><br><span class="line"><span class="string">  &lt;/p&gt;</span></span><br><span class="line"><span class="string">  &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.p.contents)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.p.children)</span><br><span class="line"><span class="comment"># 得到p标签下的子节点</span></span><br><span class="line"><span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.p.children):</span><br><span class="line">    <span class="built_in">print</span>(i, child)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果要得到所有的子孙节点的话，可以调用 descendants 属性</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.descendants)  <span class="comment"># &lt;generator object Tag.descendants at 0x00000143C3039EC8&gt;</span></span><br><span class="line"><span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.p.descendants):</span><br><span class="line">    <span class="built_in">print</span>(i, child)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>父节点和祖先节点</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">父节点和祖先节点</span></span><br><span class="line"><span class="string">如果要获取某个节点元素的父节点，可以调用 parent 属性</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.a.parent)</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.a.parents))  <span class="comment"># &lt;class &#x27;generator&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">enumerate</span>(soup.a.parents))[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>兄弟节点</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Next Sibling&#x27;</span>, soup.a.next_sibling)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Prev Sibling&#x27;</span>, soup.a.previous_sibling)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Next Siblings&#x27;</span>, <span class="built_in">list</span>(<span class="built_in">enumerate</span>(soup.a.next_siblings)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Prev Siblings&#x27;</span>, <span class="built_in">list</span>(<span class="built_in">enumerate</span>(soup.a.previous_siblings)))</span><br><span class="line"><span class="comment"># next_sibling 和 previous_sibling 分别获取节点的下一个和上一个兄弟元素，</span></span><br><span class="line"><span class="comment"># next_siblings 和 previous_siblings 分别返回所有前面和后面的兄弟节点的生成器。</span></span><br></pre></td></tr></table></figure>

<p>###3.2.4 方法选择器</p>
<ul>
<li>find_all()</li>
</ul>
<p>查询所有符合条件的元素</p>
<p>API 如下：</p>
<p>find_all(name , attrs , recursive , text , **kwargs) </p>
<ol>
<li>name。根据节点名来查询元素</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">html = <span class="string">&#x27;&#x27;&#x27;&lt;div class=&quot;panel&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;div class=&quot;panel-heading&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;h4&gt;Hello&lt;/h4&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt; </span></span><br><span class="line"><span class="string">&lt;div class=&quot;panel-body&quot;&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;list&quot; id=&quot;list-1&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;ul&gt;</span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Fool&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;/ul&gt; </span></span><br><span class="line"><span class="string">&lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;/ul&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.find(name=<span class="string">&#x27;ul&#x27;</span>)))  <span class="comment"># &lt;class &#x27;bs4.element.Tag&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.find_all(name=<span class="string">&#x27;ul&#x27;</span>)))  <span class="comment"># &lt;class &#x27;bs4.element.ResultSet&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.find_all(name=<span class="string">&#x27;ul&#x27;</span>)[<span class="number">0</span>]))  <span class="comment"># &lt;class &#x27;bs4.element.Tag&#x27;&gt;</span></span><br><span class="line"><span class="keyword">for</span> ul <span class="keyword">in</span> soup.find_all(name=<span class="string">&#x27;ul&#x27;</span>):</span><br><span class="line">    <span class="comment"># print(ul.find_all(name=&#x27;li&#x27;))</span></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> ul.find_all(name=<span class="string">&#x27;li&#x27;</span>):</span><br><span class="line">        <span class="built_in">print</span>(li.string)</span><br><span class="line">        <span class="built_in">print</span>(li[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(li)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>attrs。根据属性来查询。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">html = <span class="string">&#x27;&#x27;&#x27;&lt;div class=&quot;panel&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;div class=&quot;panel-heading&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;h4&gt;Hello&lt;/h4&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt; </span></span><br><span class="line"><span class="string">&lt;div class=&quot;panel-body&quot;&gt; </span></span><br><span class="line"><span class="string">&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;/ul&gt;</span></span><br><span class="line"><span class="string">&lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; </span></span><br><span class="line"><span class="string">&lt;/ul&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.find_all(attrs=&#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;list-1&#x27;</span>&#125;))</span><br><span class="line"><span class="comment"># print(soup.find_all(id=&#x27;list-1&#x27;))</span></span><br><span class="line"><span class="comment"># print(soup.find_all(attrs=&#123;&#x27;name&#x27;: &#x27;elements&#x27;&#125;))</span></span><br><span class="line"><span class="comment"># print(type(soup.find_all(attrs=&#123;&#x27;name&#x27;: &#x27;elements&#x27;&#125;)))  # &lt;class &#x27;bs4.element.ResultSet&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>text。匹配节点的文本，传入的形式可以是字符串，可以是正则表达式对象。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">text</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-body&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;a&gt;Hello, this is a link&lt;/a&gt; </span></span><br><span class="line"><span class="string">&lt;a&gt;Hello, this is a link, too&lt;/a&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt; </span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;这里有两个a节点，其内部包含文本信息。这里在find_all()方法 传人 text 参数 该参数为正</span></span><br><span class="line"><span class="string">则表达式对象，结果返回所有匹配正则表达式的节点文本组成的列表。&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.find_all(text=re.<span class="built_in">compile</span>(<span class="string">&#x27;link&#x27;</span>)))  <span class="comment"># [&#x27;Hello, this is a link&#x27;, &#x27;Hello, this is a link, too&#x27;]</span></span><br></pre></td></tr></table></figure>

<ul>
<li>find()。返回的是单个元素 ，也就是第一个匹配的元素。</li>
</ul>
<h1 id="第四章、数据存储"><a href="#第四章、数据存储" class="headerlink" title="第四章、数据存储"></a>第四章、数据存储</h1><p><img src="C:\Users\Aunean\AppData\Roaming\Typora\typora-user-images\image-20201124155850837.png"></p>
<h2 id="4-1-文件存储"><a href="#4-1-文件存储" class="headerlink" title="4.1 文件存储"></a>4.1 文件存储</h2><h3 id="4-1-1-TXT-文本存储"><a href="#4-1-1-TXT-文本存储" class="headerlink" title="4.1.1 TXT 文本存储"></a>4.1.1 TXT 文本存储</h3><blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;使用Python打开文件，有两种写法。</span><br><span class="line">&gt;第<span class="number">1</span>种方式如下：</span><br><span class="line">&gt;f = <span class="built_in">open</span>(<span class="string">&#x27;文件路径&#x27;</span>, <span class="string">&#x27;文件操作方式&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">&gt;对文件进行操作</span><br><span class="line">&gt;f.close()</span><br><span class="line"></span><br><span class="line">&gt;第<span class="number">2</span>种方式，使用Python的上下文管理器：</span><br><span class="line">&gt;<span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;文件路径&#x27;</span>, <span class="string">&#x27;文件操作方式&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">  对文件进行操作</span><br><span class="line"></span><br><span class="line">&gt;第<span class="number">1</span>种方式需要手动关闭文件，但是在程序开发中经常会出现忘记关闭文件的情况。</span><br><span class="line">&gt;第<span class="number">2</span>种方法不需要手动关闭文件，只要代码退出了缩进，Python就会自动关闭文件。 </span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">使用Python写文本文件</span><br><span class="line">    使用Python写文件也需要先打开文件，使用如下代码来打开文件：</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;new.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;../text.txt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    content_list = f.readlines()  <span class="comment"># 读取所有行，以列表形式返回结果</span></span><br><span class="line">    <span class="comment"># content_list = f.read()  # 直接把文件里面的全部内容用一个字符串返回</span></span><br><span class="line">    <span class="comment"># content_list = f.readline()  # 读取一行数据</span></span><br><span class="line">    <span class="built_in">print</span>(content_list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;../text2.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&quot;hello,world\n&quot;</span>)</span><br><span class="line">    <span class="comment"># f.write(&quot;hello,python&quot;)</span></span><br><span class="line">    f.writelines([<span class="string">&#x27;\n第一段\n&#x27;</span>, <span class="string">&#x27;第二段&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-JSON-文件存储"><a href="#4-1-2-JSON-文件存储" class="headerlink" title="4.1.2 JSON 文件存储"></a>4.1.2 JSON 文件存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用 JSON 库的 loads() 方法将 JSON 文本字符串转为 JSON 对象。</span></span><br><span class="line"><span class="comment"># 通过 dumps() 方法将 JSON 对象转为文本字符串。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">data = [&#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;王伟&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;gender&#x27;</span>: <span class="string">&#x27;男&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;birthday&#x27;</span>: <span class="string">&#x27;1992-10-18&#x27;</span>&#125;]</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data3.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    <span class="comment"># 这里为了输出中文，要指定参数 ensure_ascii 为 false</span></span><br><span class="line">    file.write(json.dumps(data, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-CSV-文件存储"><a href="#4-1-3-CSV-文件存储" class="headerlink" title="4.1.3 CSV 文件存储"></a>4.1.3 CSV 文件存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">data = [</span><br><span class="line">    &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">1001</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Mike1&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">10</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">1002</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Mike2&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">20</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">1003</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;子&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">30</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">1003</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Mike3&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">30</span>&#125;</span><br><span class="line">]</span><br><span class="line"><span class="comment"># newline=&#x27;&#x27;不空行</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data3.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    fieldnames = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">    writer = csv.DictWriter(f, fieldnames=fieldnames)</span><br><span class="line">    writer.writeheader()</span><br><span class="line">    writer.writerows(data)</span><br></pre></td></tr></table></figure>





<h2 id="4-2-关系型数据库存储"><a href="#4-2-关系型数据库存储" class="headerlink" title="4.2 关系型数据库存储"></a>4.2 关系型数据库存储</h2><h3 id="4-2-1-MySQL-的存储"><a href="#4-2-1-MySQL-的存储" class="headerlink" title="4.2.1 MySQL 的存储"></a>4.2.1 MySQL 的存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_data_mysql</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="comment"># 1.连接数据库</span></span><br><span class="line">    conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;qaz3357375&#x27;</span>, port=<span class="number">3306</span>, db=<span class="string">&#x27;spiders&#x27;</span>, charset=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">    cursor = conn.cursor()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建数据库</span></span><br><span class="line">	<span class="comment"># cursor.execute(&#x27;CREATE DATABASE if not exists spiders DEFAULT CHARACTER SET utf8&#x27;)</span></span><br><span class="line">    <span class="comment"># cursor.execute(&#x27;use spiders&#x27;)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2.创建表</span></span><br><span class="line">    sql = <span class="string">&#x27;create table if not exists zhaopin(position varchar(235), &#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;salary varchar(235), &#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;work_place varchar(235), &#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;Number_recruiters varchar(235), &#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;operating_duty varchar(235), &#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;requirement varchar(235), &#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;Release_time varchar(235)&#x27;</span> \</span><br><span class="line">          <span class="string">&#x27;)charset utf8&#x27;</span></span><br><span class="line"></span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    <span class="comment"># 3.插入数据</span></span><br><span class="line">    table = <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">    keys = <span class="string">&#x27;,&#x27;</span>.join(data.keys())</span><br><span class="line">    values = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&#x27;%s&#x27;</span>] * <span class="built_in">len</span>(data))</span><br><span class="line">    sql = <span class="string">&#x27;insert into &#123;table&#125;(&#123;keys&#125;) values(&#123;values&#125;)&#x27;</span>.<span class="built_in">format</span>(table=table, keys=keys, values=values)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> cursor.execute(sql, <span class="built_in">tuple</span>(data.values())):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Successful&#x27;</span>)</span><br><span class="line">            db.commit()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Failed&#x27;</span>)</span><br><span class="line">        db.rollback()</span><br><span class="line">    <span class="comment"># 关闭连接</span></span><br><span class="line">    db.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据导入</span></span><br><span class="line">conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;qaz3357375&#x27;</span>, port=<span class="number">3306</span>, db=<span class="string">&#x27;spiders&#x27;</span>, local_infile=<span class="number">1</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">&#x27;create table if not exists house_data(&#x27;</span> \</span><br><span class="line"><span class="string">&#x27;title varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;type varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;area varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;price_square_meter &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;total_price varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;orientation varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;floor varchar(1235), &#x27;</span> \</span><br><span class="line"><span class="string">&#x27;address varchar(1235)&#x27;</span> \</span><br><span class="line"><span class="string">&#x27;)charset utf8&#x27;</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    sql = <span class="string">&quot;load data local infile &#x27;路径/文件名.csv&#x27; into table 表名 fields terminated by &#x27;,&#x27; lines terminated by &#x27;\n&#x27; ignore 1 lines&quot;</span></span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    conn.commit()</span><br><span class="line">    	<span class="built_in">print</span>(<span class="string">&#x27;成功&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;失败&#x27;</span>)</span><br><span class="line"></span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>





<h2 id="4-3-非关系型数据库存储"><a href="#4-3-非关系型数据库存储" class="headerlink" title="4.3 非关系型数据库存储"></a>4.3 非关系型数据库存储</h2><h3 id="4-3-1-MongoDB-存储"><a href="#4-3-1-MongoDB-存储" class="headerlink" title="4.3.1 MongoDB 存储"></a>4.3.1 MongoDB 存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_data_mongodb</span>(<span class="params">data_list</span>):</span></span><br><span class="line">    <span class="comment"># 1.连接MongoDB</span></span><br><span class="line">    client = pymongo.MongoClient(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">27017</span>)</span><br><span class="line">    <span class="comment">#  指定数据库</span></span><br><span class="line">    db = client[<span class="string">&#x27;数据库名&#x27;</span>]</span><br><span class="line">    <span class="comment"># 指定集合</span></span><br><span class="line">    collection = db[<span class="string">&#x27;集合名&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        collection.insert_one(i)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_data_mongo</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="comment"># 1.连接MongoDB</span></span><br><span class="line">    client = pymongo.MongoClient(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">27017</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.指定数据库</span></span><br><span class="line">    db = client[<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.指定集合</span></span><br><span class="line">    collection = db[<span class="string">&#x27;zhaopin&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.插入多条数据</span></span><br><span class="line">    collection.insert_many(data)</span><br></pre></td></tr></table></figure>





<h1 id="第五章、Ajax数据爬取"><a href="#第五章、Ajax数据爬取" class="headerlink" title="第五章、Ajax数据爬取"></a>第五章、Ajax数据爬取</h1><h1 id="第六章、动态渲染页面爬取"><a href="#第六章、动态渲染页面爬取" class="headerlink" title="第六章、动态渲染页面爬取"></a>第六章、动态渲染页面爬取</h1><h2 id="6-1-Selenium-的使用"><a href="#6-1-Selenium-的使用" class="headerlink" title="6.1 Selenium 的使用"></a>6.1 Selenium 的使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">    <span class="built_in">input</span> = browser.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)</span><br><span class="line">    <span class="built_in">input</span>.send_keys(<span class="string">&#x27;Python&#x27;</span>)</span><br><span class="line">    <span class="built_in">input</span>.send_keys(Keys.ENTER)</span><br><span class="line">    wait = WebDriverWait(browser, <span class="number">100</span>)</span><br><span class="line">    wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;content_left&#x27;</span>)))</span><br><span class="line">    <span class="built_in">print</span>(browser.current_url)</span><br><span class="line">    <span class="built_in">print</span>(browser.get_cookies())</span><br><span class="line">    <span class="built_in">print</span>(browser.page_source)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Error&#x27;</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>访问页面</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>查找节点</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单节点</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line">input_first = browser.find_element_by_id(<span class="string">&#x27;q&#x27;</span>)  <span class="comment"># 根据 id 值查找</span></span><br><span class="line">input_second = browser.find_element_by_css_selector(<span class="string">&#x27;#q&#x27;</span>)</span><br><span class="line">input_third = browser.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;q&quot;]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(input_first, input_second, input_third)</span><br><span class="line">browser.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多节点</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line">lis = browser.find_elements_by_xpath(<span class="string">&#x27;/html/body/div[4]/div[1]/div/div[1]/div/ul/li&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(lis)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>获取属性</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取属性</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line">logo = browser.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;special&quot;]/div[2]/div/div[2]/a/img&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(logo)</span><br><span class="line">src = logo.get_attribute(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line"><span class="comment"># print(src)</span></span><br><span class="line">tp = requests.get(url=src).content</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;图片.png&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(tp)</span><br><span class="line"><span class="comment"># browser.close()</span></span><br></pre></td></tr></table></figure>

<ul>
<li>获取文本</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_xpath(<span class="string">&#x27;/html/body/div[1]/div/main/div[2]/div[3]/div[2]/div/div[3]/div[2]/div[1]/a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.text)</span><br></pre></td></tr></table></figure>































































<h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="1-使用框架爬取猫眼top100的信息"><a href="#1-使用框架爬取猫眼top100的信息" class="headerlink" title="1. 使用框架爬取猫眼top100的信息"></a>1. 使用框架爬取猫眼top100的信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># maoyan.py 这里是文件名</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> maoyanPro.items <span class="keyword">import</span> MaoyanproItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaoyanSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;maoyan&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;https://maoyan.com/board/4?offset=0&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://maoyan.com/board/4?offset=0&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        dd_list = response.xpath(<span class="string">&#x27;//*[@id=&quot;app&quot;]/div/div/div[1]/dl/dd&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(dd_list)</span></span><br><span class="line">        <span class="keyword">for</span> dd <span class="keyword">in</span> dd_list:</span><br><span class="line">            item = MaoyanproItem()</span><br><span class="line">            item[<span class="string">&quot;title&quot;</span>] = dd.xpath(<span class="string">&#x27;./a/@title&#x27;</span>).extract_first()</span><br><span class="line">            item[<span class="string">&quot;actor&quot;</span>] = (<span class="string">&#x27;&#x27;</span>.join(dd.xpath(<span class="string">&#x27;./div//p[@class=&quot;star&quot;]/text()&#x27;</span>).extract()).strip())[<span class="number">3</span>:]</span><br><span class="line">            item[<span class="string">&quot;time&quot;</span>] = dd.xpath(<span class="string">&#x27;./div//p[@class=&quot;releasetime&quot;]/text()&#x27;</span>).extract_first()[<span class="number">5</span>:]</span><br><span class="line">            item[<span class="string">&quot;score&quot;</span>] = <span class="string">&#x27;&#x27;</span>.join(dd.css(<span class="string">&#x27;p.score i::text&#x27;</span>).extract())</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        next_url = response.xpath(<span class="string">&#x27;//*[@id=&quot;app&quot;]//div[2]/ul/li[last()]/a/@href&#x27;</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_url != <span class="string">&#x27;javascript:void(0);&#x27;</span>:</span><br><span class="line">            next_url = <span class="string">&#x27;https://maoyan.com/board/4&#x27;</span> + next_url</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">         </span><br><span class="line">        </span><br><span class="line"><span class="comment"># items.py 这里是文件名            </span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaoyanproItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    actor = scrapy.Field()</span><br><span class="line">    time = scrapy.Field()</span><br><span class="line">    score = scrapy.Field()</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># pipelines.py 这里是文件名</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> maoyanPro.items <span class="keyword">import</span> MaoyanproItem</span><br><span class="line"></span><br><span class="line"><span class="comment"># client = pymongo.MongoClient(host=&#x27;localhost&#x27;, port=27017)</span></span><br><span class="line"><span class="comment"># db = client[&#x27;test&#x27;]</span></span><br><span class="line"><span class="comment"># collection = db[&#x27;maoyan_2&#x27;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># class MaoyanproPipeline(object):</span></span><br><span class="line"><span class="comment">#     def process_item(self, item, spider):</span></span><br><span class="line"><span class="comment">#         print(item)</span></span><br><span class="line"><span class="comment">#         collection.insert_one(dict(item))</span></span><br><span class="line"><span class="comment">#         return item</span></span><br><span class="line"><span class="comment"># import pymysql</span></span><br><span class="line"><span class="comment"># from maoyan import settings</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaoyanPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        title = item[<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">        actor = item[<span class="string">&#x27;actor&#x27;</span>]</span><br><span class="line">        time = item[<span class="string">&#x27;time&#x27;</span>]</span><br><span class="line">        score = item[<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">        <span class="comment"># ********** Begin **********#</span></span><br><span class="line">        <span class="comment"># 1.连接数据库</span></span><br><span class="line">        conn = pymysql.connect(</span><br><span class="line">            host=<span class="string">&#x27;localhost&#x27;</span>,  <span class="comment"># 连接的是本地数据库</span></span><br><span class="line">            port=<span class="number">3306</span>,  <span class="comment"># 数据库端口名</span></span><br><span class="line">            user=<span class="string">&#x27;root&#x27;</span>,  <span class="comment"># 自己的mysql用户名</span></span><br><span class="line">            passwd=<span class="string">&#x27;qaz3357375&#x27;</span>,  <span class="comment"># 自己的密码</span></span><br><span class="line">            db=<span class="string">&#x27;spiders&#x27;</span>,  <span class="comment"># 数据库的名字</span></span><br><span class="line">            charset=<span class="string">&#x27;utf8&#x27;</span>,  <span class="comment"># 默认的编码方式</span></span><br><span class="line">        )</span><br><span class="line">        cursor = conn.cursor()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            sql = <span class="string">&#x27;create table if not exists mymovies(title varchar(235), actor varchar(235), time varchar(235), score varchar(235))charset utf8&#x27;</span></span><br><span class="line">            cursor.execute(sql)</span><br><span class="line">            <span class="comment"># sql = &#x27;insert into mymovies values (\&#x27;%s\&#x27;,\&#x27;%s\&#x27;,\&#x27;%s\&#x27;,\&#x27;%s\&#x27;)&#x27; % (name, starts, releasetime, score)</span></span><br><span class="line">            sql = <span class="string">&#x27;insert into mymovies values (&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;)&#x27;</span> % (title, actor, time, score)</span><br><span class="line">            <span class="built_in">print</span>(title+<span class="string">&quot;插入成功&quot;</span>)</span><br><span class="line">            cursor.execute(sql)</span><br><span class="line">            conn.commit()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;错误：<span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            conn.close()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>



<h2 id="2-爬取豆瓣电影数据"><a href="#2-爬取豆瓣电影数据" class="headerlink" title="2. 爬取豆瓣电影数据"></a>2. 爬取豆瓣电影数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">需求分析：</span></span><br><span class="line"><span class="string">此网站为ajax加载</span></span><br><span class="line"><span class="string">1.爬豆瓣电影数据的名称，评分，图片，视频url。</span></span><br><span class="line"><span class="string">2.写入到csv和MySQL数据库</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://www.douban.com&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://movie.douban.com/&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://movie.douban.com/explore#!type=movie&amp;tag=%E6%9C%80%E6%96%B0&amp;page_limit=20&amp;page_start=0&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://movie.douban.com/j/search_subjects?type=movie&amp;tag=%E6%9C%80%E6%96%B0&amp;page_limit=20&amp;page_start=0&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://movie.douban.com/explore#!type=movie&amp;tag=%E6%9C%80%E6%96%B0&amp;page_limit=20&amp;page_start=20&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">response_url</span>(<span class="params">url</span>):</span></span><br><span class="line">    data_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">100</span>, <span class="number">20</span>):</span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;movie&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;tag&#x27;</span>: <span class="string">&#x27;最新&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;page_limit&#x27;</span>: <span class="string">&#x27;20&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;page_start&#x27;</span>: i</span><br><span class="line">        &#125;</span><br><span class="line">        response = requests.get(url=url, params=params, headers=headers).json()</span><br><span class="line">        <span class="keyword">for</span> movie <span class="keyword">in</span> response[<span class="string">&#x27;subjects&#x27;</span>]:</span><br><span class="line">            title = movie[<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">            score = movie[<span class="string">&#x27;rate&#x27;</span>]</span><br><span class="line">            video_url = movie[<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">            img = movie[<span class="string">&#x27;cover&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span>: title,</span><br><span class="line">                <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">                <span class="string">&#x27;video_url&#x27;</span>: video_url,</span><br><span class="line">                <span class="string">&#x27;img&#x27;</span>: img</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">print</span>(data)</span><br><span class="line">            data_list.append(data)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 存储图片</span></span><br><span class="line">            path = <span class="string">&#x27;douban_img/&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">                os.makedirs(path)</span><br><span class="line">            img_data = requests.get(url=img, headers=headers).content</span><br><span class="line">            img_name = img.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(path+img_name, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(img_data)</span><br><span class="line">    <span class="comment"># insert_csv(data_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_csv</span>(<span class="params">data_list</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./豆瓣.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        fieldnames = [<span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;score&#x27;</span>, <span class="string">&#x27;video_url&#x27;</span>, <span class="string">&#x27;img&#x27;</span>]</span><br><span class="line">        writer = csv.DictWriter(f, fieldnames=fieldnames)</span><br><span class="line">        writer.writeheader()</span><br><span class="line">        writer.writerows(data_list)</span><br><span class="line">    <span class="comment"># insert_mysql()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_mysql</span>():</span></span><br><span class="line">    conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">3306</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;qaz3357375&#x27;</span>, db=<span class="string">&#x27;spiders2&#x27;</span>, local_infile=<span class="number">1</span>)</span><br><span class="line">    cursor = conn.cursor()</span><br><span class="line">    sql = <span class="string">&#x27;create table if not exists douban(title varchar(235), score varchar(235), video_url varchar(235), img varchar(235))&#x27;</span></span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        sql = <span class="string">&quot;load data local infile &#x27;D:/learning/spider/project/爬虫案例/豆瓣.csv&#x27; into table douban fields terminated by &#x27;,&#x27; lines terminated by &#x27;\n&#x27; ignore 1 lines&quot;</span></span><br><span class="line">        cursor.execute(sql)</span><br><span class="line">        conn.commit()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;错误：<span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://movie.douban.com/j/search_subjects?&#x27;</span></span><br><span class="line">    response_url(url)</span><br></pre></td></tr></table></figure>



<p>##3.爬取小说</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> parsel</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;https://www.xsbiquge.com&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://www.xsbiquge.com/20_20331/1135932.html&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://www.xsbiquge.com/20_20331/1135933.html&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;www.xsbiquge.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate, br&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.baidu.com/link?url=gREzciPAbw8dLQOU3UGpX-fvNBEUVHtO7HU5hwdzIgWZIbq9jRhRSkYosvPBCdRP&amp;wd=&amp;eqid=cf2722fb00007d98000000045fb2203b&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;PPad_id_PP=3; bcolor=; font=; size=; fontcolor=; width=&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Upgrade-Insecure-Requests&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;If-Modified-Since&#x27;</span>: <span class="string">&#x27;Sun, 15 Nov 2020 16:52:47 GMT&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;If-None-Match&#x27;</span>: <span class="string">&#x27;W/&quot;5fb15cdf-353e1&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cache-Control&#x27;</span>: <span class="string">&#x27;max-age=0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">urls_info</span>(<span class="params">url</span>):</span></span><br><span class="line">    response = requests.get(url, headers=headers).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(response)</span></span><br><span class="line">    sel = parsel.Selector(response)</span><br><span class="line">    htmls = []</span><br><span class="line">    use_info = sel.css(<span class="string">&#x27;dl dd a::attr(href)&#x27;</span>).getall()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> use_info:</span><br><span class="line">        htmls.append(url + (i[<span class="number">10</span>:]))</span><br><span class="line">    <span class="comment"># print(htmls)</span></span><br><span class="line">    page_content(htmls)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&lt;dl&gt;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&lt;dd&gt;&lt;a href=&quot;/20_20331/1135932.html&quot;&gt;第1章 八百年后&lt;/a&gt;&lt;/dd&gt;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&lt;/dl&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">page_content</span>(<span class="params">htmls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> html <span class="keyword">in</span> htmls:</span><br><span class="line">        response = requests.get(html, headers=headers).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        path = <span class="string">&#x27;02_万古神帝/&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            os.makedirs(path)</span><br><span class="line"></span><br><span class="line">        sel = parsel.Selector(response)</span><br><span class="line">        title = sel.css(<span class="string">&#x27;h1::text&#x27;</span>).get()</span><br><span class="line">        <span class="built_in">print</span>(title)</span><br><span class="line">        contents = sel.css(<span class="string">&#x27;div#content::text&#x27;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> content <span class="keyword">in</span> contents:</span><br><span class="line">            content = <span class="built_in">str</span>(content).replace(<span class="string">&#x27;&amp;#039&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(path+<span class="built_in">str</span>(title)+<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(content + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;html body div#wrapper div.content_read div.box_con div#content&#x27;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://www.xsbiquge.com/20_20331/&#x27;</span></span><br><span class="line">    urls_info(url)</span><br></pre></td></tr></table></figure>



<h2 id="4-使用scrapy框架爬取小说"><a href="#4-使用scrapy框架爬取小说" class="headerlink" title="4.使用scrapy框架爬取小说"></a>4.使用scrapy框架爬取小说</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> wanguPro.items <span class="keyword">import</span> WanguproItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WanguSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;wangu&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;www.xsbiquge.com/20_20331/&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.xsbiquge.com/20_20331//&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        detail_urls = response.xpath(<span class="string">&#x27;//div[@id=&quot;list&quot;]/dl/dd/a/@href&#x27;</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">            detail_url = <span class="string">&#x27;https://www.xsbiquge.com&#x27;</span> + detail_url</span><br><span class="line">            <span class="comment"># print(detail_url)</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(detail_url, callback=self.detail_parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        title = response.xpath(<span class="string">&#x27;//h1/text()&#x27;</span>).extract_first()</span><br><span class="line">        content = <span class="string">&#x27;&#x27;</span>.join(response.xpath(<span class="string">&#x27;//div[@id=&quot;content&quot;]/text()&#x27;</span>).extract()).replace(<span class="string">&#x27;\xa0\xa0\xa0\xa0&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;&amp;#039;&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(title)</span></span><br><span class="line">        item = WanguproItem()</span><br><span class="line">        item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">        item[<span class="string">&#x27;content&#x27;</span>] = content</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WanguproPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        path = <span class="string">&#x27;万古神帝/&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            os.mkdir(path)</span><br><span class="line">        title = item[<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">        title = title.replace(<span class="string">&#x27;?&#x27;</span>, <span class="string">&#x27;？&#x27;</span>)</span><br><span class="line">        content = item[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;title&#125;</span> 写入成功&#x27;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path+title+<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(content)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h2 id="5-爬取前程无忧招聘数据-正则"><a href="#5-爬取前程无忧招聘数据-正则" class="headerlink" title="5.爬取前程无忧招聘数据(正则)"></a>5.爬取前程无忧招聘数据(正则)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="string">&#x27;https://search.51job.com&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://search.51job.com/list/190000,000000,0000,00,9,99,Java,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://search.51job.com/list/190000,000000,0000,00,9,99,python,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://search.51job.com/list/190000,000000,0000,00,9,99,python,2,2.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=&#x27;</span></span><br><span class="line"><span class="string">&#x27;https://search.51job.com/list/190000,000000,0000,00,9,99,python,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">lang: c</span></span><br><span class="line"><span class="string">postchannel: 0000</span></span><br><span class="line"><span class="string">workyear: 99</span></span><br><span class="line"><span class="string">cotype: 99</span></span><br><span class="line"><span class="string">degreefrom: 99</span></span><br><span class="line"><span class="string">jobterm: 99</span></span><br><span class="line"><span class="string">companysize: 99</span></span><br><span class="line"><span class="string">ord_field: 0</span></span><br><span class="line"><span class="string">dibiaoid: 0</span></span><br><span class="line"><span class="string">line: </span></span><br><span class="line"><span class="string">welfare: </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">word = <span class="built_in">input</span>(<span class="string">&#x27;请输入搜索关键字：&#x27;</span>)</span><br><span class="line">base_url = <span class="string">&#x27;https://search.51job.com/list/190000,000000,0000,00,9,99,&#123;&#125;,2,&#123;&#125;.html?&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;lang&#x27;</span>: <span class="string">&#x27;c&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;postchannel&#x27;</span>: <span class="string">&#x27;0000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;workyear&#x27;</span>: <span class="string">&#x27;99&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cotype&#x27;</span>: <span class="string">&#x27;99&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;degreefrom&#x27;</span>: <span class="string">&#x27;99&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;jobterm&#x27;</span>: <span class="string">&#x27;99&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;companysize&#x27;</span>: <span class="string">&#x27;99&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ord_field&#x27;</span>: <span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;dibiaoid&#x27;</span>: <span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;line&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;welfare&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">end_page = <span class="built_in">input</span>(<span class="string">&quot;请输入结束页：&quot;</span>)</span><br><span class="line">data_list = []</span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">int</span>(end_page) + <span class="number">1</span>):</span><br><span class="line">    url = base_url.<span class="built_in">format</span>(word, end_page)</span><br><span class="line">    response = requests.get(url=url, params=params, headers=headers).content.decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(response)</span></span><br><span class="line">    <span class="comment"># position = re.findall(r&#x27;&#x27;, response, re.S)</span></span><br><span class="line">    <span class="comment"># work_place = re.findall(r&#x27;&#x27;, response, re.S)</span></span><br><span class="line">    <span class="comment"># salary = re.findall(r&#x27;&#x27;, response, re.S)[0]</span></span><br><span class="line">    <span class="comment"># update = re.findall(r&#x27;&#x27;, response, re.S)</span></span><br><span class="line">    <span class="comment"># welfare = re.findall(r&#x27;&#x27;, response, re.S)</span></span><br><span class="line">    <span class="comment"># company = re.findall(r&#x27;&#x27;, response, re.S)</span></span><br><span class="line">    <span class="comment"># company_type = re.findall(r&#x27;&#x27;, response, re.S)</span></span><br><span class="line">    <span class="comment"># work_year = re.findall(r&#x27;&#x27;,response, re.S)</span></span><br><span class="line">    pattern = <span class="string">r&#x27;&quot;job_name&quot;:&quot;(.*?)&quot;.*?&quot;company_name&quot;:&quot;(.*?)&quot;.*?providesalary_text&quot;:&quot;(.*?)&quot;.*?&quot;workarea_text&quot;:&quot;(.*?)&quot;.*?companytype_text&quot;:&quot;(.*?)&quot;.*?workyear&quot;:&quot;(.*?)&quot;.*?&quot;issuedate&quot;:&quot;(.*?)&quot;.*?jobwelf&quot;:&quot;(.*?)&quot;&#x27;</span></span><br><span class="line">    content = re.findall(pattern, response, re.S)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="keyword">for</span> info <span class="keyword">in</span> content:</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&#x27;position&#x27;</span>: info[<span class="number">0</span>].replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;company&#x27;</span>: info[<span class="number">1</span>],</span><br><span class="line">            <span class="string">&#x27;salary&#x27;</span>: info[<span class="number">2</span>].replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;work_place&#x27;</span>: info[<span class="number">3</span>],</span><br><span class="line">            <span class="string">&#x27;company_type&#x27;</span>: info[<span class="number">4</span>],</span><br><span class="line">            <span class="string">&#x27;work_year&#x27;</span>: info[<span class="number">5</span>],</span><br><span class="line">            <span class="string">&#x27;update&#x27;</span>: info[<span class="number">6</span>],</span><br><span class="line">            <span class="string">&#x27;welfare&#x27;</span>: info[<span class="number">7</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        data_list.append(data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;前程.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    fieldnames = [<span class="string">&#x27;position&#x27;</span>, <span class="string">&#x27;company&#x27;</span>, <span class="string">&#x27;salary&#x27;</span>, <span class="string">&#x27;work_place&#x27;</span>, <span class="string">&#x27;company_type&#x27;</span>, <span class="string">&#x27;work_year&#x27;</span>, <span class="string">&#x27;update&#x27;</span>, <span class="string">&#x27;welfare&#x27;</span>]</span><br><span class="line">    writer = csv.DictWriter(f, fieldnames=fieldnames)</span><br><span class="line">    writer.writeheader()</span><br><span class="line">    writer.writerows(data_list)</span><br></pre></td></tr></table></figure>

<p>##6.爬取图片（使用xpath）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">            <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    urls = [<span class="string">&#x27;http://pic.netbian.com/4kdongman/index_&#123;&#125;.html&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">147</span>)]</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        response = requests.get(url, headers=headers).text</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 数据解析</span></span><br><span class="line">        tree = etree.HTML(response)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./picLibs_dongman&#x27;</span>):</span><br><span class="line">            os.mkdir(<span class="string">&#x27;./picLibs_dongman&#x27;</span>)</span><br><span class="line">        li_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            img_href = li.xpath(<span class="string">&#x27;./a/@href&#x27;</span>)[<span class="number">0</span>]  <span class="comment"># /tupian/26531.html</span></span><br><span class="line">            img_href = <span class="string">&#x27;http://pic.netbian.com&#x27;</span>+img_href</span><br><span class="line">            <span class="comment"># print(img_href)  # http://pic.netbian.com/tupian/26531.html</span></span><br><span class="line"></span><br><span class="line">            response = requests.get(url=img_href, headers=headers).text</span><br><span class="line">            tree = etree.HTML(response)</span><br><span class="line">            img_src = tree.xpath(<span class="string">&#x27;//div[@class=&quot;photo-pic&quot;]/a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">            img_src = <span class="string">&#x27;http://pic.netbian.com&#x27;</span>+img_src</span><br><span class="line">            <span class="comment"># print(img_src)  # http://pic.netbian.com/uploads/allimg/201113/003901-1605199141caf8.jpg</span></span><br><span class="line"></span><br><span class="line">            img_name = tree.xpath(<span class="string">&#x27;//div[@class=&quot;photo-pic&quot;]/a/img/@title&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">            img_name = img_name+<span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">            img_name = img_name.encode(<span class="string">&#x27;iso-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            img_data = requests.get(url=img_src, headers=headers).content</span><br><span class="line"></span><br><span class="line">            img_path = <span class="string">&#x27;picLibs_dongman/&#x27;</span>+img_name</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(img_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(img_data)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;img_name&#125;</span> 下载成功&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>##7.爬取招聘信息（xpath,base64）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import base64</span><br><span class="line">import csv</span><br><span class="line">import pymysql</span><br><span class="line">from lxml import etree</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;getPosition?id&#x3D;MTA4MQ&#x3D;&#x3D;&#39;</span><br><span class="line">&#39;id&#x3D;&quot;1082&quot;&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;getPosition?id&#x3D;MTA4Mg&#x3D;&#x3D;&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;getPosition?id&#x3D;MTA4Mw&#x3D;&#x3D;&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;getPosition?id&#x3D;MTA4Ng&#x3D;&#x3D;&#39;</span><br><span class="line">&#39;MTA4MQ&#39;</span><br><span class="line">&#39;1081&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;MS1hbGljZQ&#x3D;&#x3D;&#x2F;12&#x2F;749&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;Mi1hbGljZQ&#x3D;&#x3D;&#x2F;12&#x2F;749&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;My1hbGljZQ&#x3D;&#x3D;&#x2F;12&#x2F;749&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;NC1hbGljZQ&#x3D;&#x3D;&#x2F;12&#x2F;749&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;NS1hbGljZQ&#x3D;&#x3D;&#x2F;12&#x2F;749&#39;</span><br><span class="line">&#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;Mi1hbGljZQ&#x3D;&#x3D;&#x2F;12&#x2F;749&#39;</span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;86.0.4240.198 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">data_list &#x3D; []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def detail_data():</span><br><span class="line">    for i in range(1, 800):</span><br><span class="line">        page &#x3D; str(i) + &#39;-alice&#39;</span><br><span class="line">        result &#x3D; base64.b64encode(page.encode()).decode()</span><br><span class="line">        url &#x3D; &#39;http:&#x2F;&#x2F;localhost:8080&#x2F;page&#x2F;&#39; + result + &#39;&#x2F;12&#x2F;749&#39;</span><br><span class="line">        response &#x3D; requests.get(url, headers&#x3D;headers).content.decode(&#39;utf-8&#39;)</span><br><span class="line">        sel &#x3D; etree.HTML(response)</span><br><span class="line">        id_list &#x3D; sel.xpath(&#39;&#x2F;&#x2F;legend&#x2F;a&#x2F;@id&#39;)</span><br><span class="line"></span><br><span class="line">        edu_level_list &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;article-list&quot;]&#x2F;&#x2F;div&#x2F;fieldset&#x2F;&#x2F;div[1]&#x2F;div[4]&#x2F;text()&#39;)</span><br><span class="line">        create_time_list &#x3D; sel.xpath(&#39;&#x2F;&#x2F;div[@class&#x3D;&quot;info&quot;]&#x2F;span[2]&#x2F;text()&#39;)</span><br><span class="line">        company_size_list &#x3D; sel.xpath(&#39;&#x2F;&#x2F;div[@class&#x3D;&quot;layui-row&quot;]&#x2F;div[@class&#x3D;&quot;layui-col-md2&quot;]&#x2F;span&#x2F;text()&#39;)</span><br><span class="line">        workingExp_list &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;article-list&quot;]&#x2F;div&#x2F;&#x2F;fieldset&#x2F;&#x2F;div[1]&#x2F;div[3] &#x2F;text()&#39;)</span><br><span class="line">        company_name_list &#x3D; []</span><br><span class="line">        job_name_list &#x3D; []</span><br><span class="line">        salary_list &#x3D; []</span><br><span class="line">        city_name_list &#x3D; []</span><br><span class="line">        welfare_list &#x3D; []</span><br><span class="line">        responsibility_list &#x3D; []</span><br><span class="line">        place_list &#x3D; []</span><br><span class="line"></span><br><span class="line">        for i in id_list:</span><br><span class="line">            result &#x3D; base64.b64encode(i.encode()).decode()</span><br><span class="line">            # print(result)</span><br><span class="line">            detail_url &#x3D; &#39;http:&#x2F;&#x2F;localhost:8080&#x2F;getPosition?id&#x3D;&#39; + result</span><br><span class="line">            # print(detail_url)</span><br><span class="line">            response &#x3D; requests.get(detail_url, headers&#x3D;headers).content.decode(&#39;utf-8&#39;)</span><br><span class="line">            sel &#x3D; etree.HTML(response)</span><br><span class="line"></span><br><span class="line">            company_name &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;affix-side&quot;]&#x2F;div[1]&#x2F;div&#x2F;div&#x2F;div[2]&#x2F;p&#x2F;text()&#39;)[0]</span><br><span class="line">            company_name_list.append(company_name)</span><br><span class="line"></span><br><span class="line">            job_name &#x3D; sel.xpath(&#39;&#x2F;&#x2F;h3&#x2F;text()&#39;)[0]</span><br><span class="line">            job_name_list.append(job_name)</span><br><span class="line"></span><br><span class="line">            salary &#x3D; sel.xpath(&#39;&#x2F;&#x2F;div[@class&#x3D;&quot;layui-card&quot;]&#x2F;div[2]&#x2F;text()&#39;)[0]</span><br><span class="line">            salary_list.append(salary)</span><br><span class="line"></span><br><span class="line">            city_name &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;affix-side&quot;]&#x2F;div[1]&#x2F;&#x2F;div[2]&#x2F;span&#x2F;text()&#39;)[0]</span><br><span class="line">            city_name_list.append(city_name)</span><br><span class="line"></span><br><span class="line">            welfare &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;article-list&quot;]&#x2F;&#x2F;div[2]&#x2F;&#x2F;div[2]&#x2F;text()&#39;)[0]</span><br><span class="line">            welfare_list.append(welfare)</span><br><span class="line"></span><br><span class="line">            if len(sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;article-list&quot;]&#x2F;&#x2F;div[3]&#x2F;&#x2F;div[2]&#x2F;text()&#39;)) &#x3D;&#x3D; 0:</span><br><span class="line">                responsibility &#x3D; &#39;null&#39;</span><br><span class="line">            else:</span><br><span class="line">                responsibility &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;article-list&quot;]&#x2F;&#x2F;div[3]&#x2F;&#x2F;div[2]&#x2F;text()&#39;)[0]</span><br><span class="line">            responsibility_list.append(responsibility)</span><br><span class="line"></span><br><span class="line">            place &#x3D; sel.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;article-list&quot;]&#x2F;&#x2F;div[4]&#x2F;div&#x2F;div[2]&#x2F;text()&#39;)[0]</span><br><span class="line">            place_list.append(place)</span><br><span class="line"></span><br><span class="line">        for i in range(len(company_name_list)):</span><br><span class="line">            data &#x3D; &#123;</span><br><span class="line">                &#39;company_name&#39;: company_name_list[i],</span><br><span class="line">                &#39;edu_level&#39;: edu_level_list[i],</span><br><span class="line">                &#39;job_name&#39;: job_name_list[i],</span><br><span class="line">                &#39;salary&#39;: salary_list[i],</span><br><span class="line">                &#39;create_time&#39;: create_time_list[i],</span><br><span class="line">                &#39;city_name&#39;: city_name_list[i],</span><br><span class="line">                &#39;company_size&#39;: company_size_list[i],</span><br><span class="line">                &#39;welfare&#39;: welfare_list[i].replace(&#39;,&#39;, &#39;，&#39;),</span><br><span class="line">                &#39;responsibility&#39;: responsibility_list[i].replace(&#39;,&#39;, &#39;，&#39;).replace(&#39;\xa0&#39;, &#39;&#39;),</span><br><span class="line">                &#39;place&#39;: place_list[i].replace(&#39;,&#39;, &#39;，&#39;),</span><br><span class="line">                &#39;workingExp&#39;: workingExp_list[i]</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            print(data)</span><br><span class="line">            data_list.append(data)</span><br><span class="line">            # insert_mysql(data)</span><br><span class="line">    insert_csv(data_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def insert_csv(data_list):</span><br><span class="line">    with open(&#39;cn_01_recruitment.csv&#39;, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;, newline&#x3D;&#39;&#39;) as f:</span><br><span class="line">        fieldnames &#x3D; [&#39;company_name&#39;, &#39;edu_level&#39;, &#39;job_name&#39;, &#39;salary&#39;, &#39;create_time&#39;, &#39;city_name&#39;, &#39;company_size&#39;,</span><br><span class="line">                      &#39;welfare&#39;, &#39;responsibility&#39;, &#39;place&#39;, &#39;workingExp&#39;]</span><br><span class="line">        writer &#x3D; csv.DictWriter(f, fieldnames&#x3D;fieldnames)</span><br><span class="line">        writer.writeheader()</span><br><span class="line">        writer.writerows(data_list)</span><br><span class="line">    load_mysql()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># def insert_mysql(data):</span><br><span class="line">#</span><br><span class="line">#     conn &#x3D; pymysql.connect(host&#x3D;&#39;localhost&#39;, user&#x3D;&#39;root&#39;, password&#x3D;&#39;root&#39;, port&#x3D;3306, db&#x3D;&#39;spiders&#39;)</span><br><span class="line">#     cursor &#x3D; conn.cursor()</span><br><span class="line">#</span><br><span class="line">#     sql &#x3D; &#39;create table if not exists recruitment ( &#39; \</span><br><span class="line">#           &#39;id int(11) primary key auto_increment, &#39; \</span><br><span class="line">#           &#39;company_name varchar(255), &#39; \</span><br><span class="line">#           &#39;edu_level varchar(255), &#39; \</span><br><span class="line">#           &#39;job_name varchar(255), &#39; \</span><br><span class="line">#           &#39;salary varchar(255), &#39; \</span><br><span class="line">#           &#39;create_time varchar(255), &#39; \</span><br><span class="line">#           &#39;city_name varchar(255), &#39; \</span><br><span class="line">#           &#39;company_size varchar(255), &#39; \</span><br><span class="line">#           &#39;welfare varchar(255), &#39; \</span><br><span class="line">#           &#39;responsibility text, &#39; \</span><br><span class="line">#           &#39;place varchar(255), &#39; \</span><br><span class="line">#           &#39;workingExp varchar(255)&#39; \</span><br><span class="line">#           &#39;)charset utf8&#39;</span><br><span class="line">#     cursor.execute(sql)</span><br><span class="line">#</span><br><span class="line">#     table &#x3D; &#39;recruitment&#39;</span><br><span class="line">#     keys &#x3D; &#39;,&#39;.join(data.keys())</span><br><span class="line">#</span><br><span class="line">#     values &#x3D; &#39;,&#39;.join([&#39;%s&#39;] * len(data))</span><br><span class="line">#     sql &#x3D; &#39;insert into &#123;table&#125;(&#123;keys&#125;) values(&#123;values&#125;)&#39;.format(table&#x3D;table, keys&#x3D;keys, values&#x3D;values)</span><br><span class="line">#     try:</span><br><span class="line">#         if cursor.execute(sql, tuple(data.values())):</span><br><span class="line">#             print(&#39;Successful&#39;)</span><br><span class="line">#             conn.commit()</span><br><span class="line">#     except Exception as e:</span><br><span class="line">#         print(&#39;Failed&#39;, e)</span><br><span class="line">#         conn.rollback()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_mysql():</span><br><span class="line">    conn &#x3D; pymysql.connect(host&#x3D;&#39;localhost&#39;, user&#x3D;&#39;root&#39;, password&#x3D;&#39;root&#39;, port&#x3D;3306, db&#x3D;&#39;spiders&#39;, local_infile&#x3D;1)</span><br><span class="line">    cursor &#x3D; conn.cursor()</span><br><span class="line">    sql &#x3D; &#39;create table if not exists recruitment ( &#39; \</span><br><span class="line">          &#39;company_name varchar(1255), &#39; \</span><br><span class="line">          &#39;edu_level varchar(1255), &#39; \</span><br><span class="line">          &#39;job_name varchar(1255), &#39; \</span><br><span class="line">          &#39;salary varchar(1255), &#39; \</span><br><span class="line">          &#39;create_time datetime, &#39; \</span><br><span class="line">          &#39;city_name varchar(1255), &#39; \</span><br><span class="line">          &#39;company_size varchar(1255), &#39; \</span><br><span class="line">          &#39;welfare varchar(1255), &#39; \</span><br><span class="line">          &#39;responsibility text, &#39; \</span><br><span class="line">          &#39;place varchar(1255), &#39; \</span><br><span class="line">          &#39;workingExp varchar(1255),&#39; \</span><br><span class="line">          &#39;id int(30) primary key auto_increment &#39; \</span><br><span class="line">          &#39;)charset utf8&#39;</span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    try:</span><br><span class="line">        sql &#x3D; &quot;load data local infile &#39;.&#x2F;cn_01_recruitment.csv&#39; into table recruitment fields terminated by &#39;,&#39; lines terminated by &#39;\n&#39; ignore 1 lines&quot;</span><br><span class="line">        cursor.execute(sql)</span><br><span class="line">        conn.commit()</span><br><span class="line">        print(&#39;成功&#39;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(&#39;失败&#39;, e)</span><br><span class="line">    finally:</span><br><span class="line">        conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    detail_data()</span><br></pre></td></tr></table></figure>

<p>##8.爬取美团酒店信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://ihotel.meituan.com/hbsearch/HotelSearch&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://hotel.meituan.com/&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>):</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;utm_medium&#x27;</span>: <span class="string">&#x27;pc&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;version_name&#x27;</span>: <span class="number">999.9</span>,</span><br><span class="line">        <span class="string">&#x27;cateId&#x27;</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="string">&#x27;attr_28&#x27;</span>: <span class="number">129</span>,</span><br><span class="line">        <span class="string">&#x27;uuid&#x27;</span>: <span class="string">&#x27; DA1E77214B957240252862761F1E15865B9B1AA2ACD29C83F0F61D03E8DFB644@1607773617614&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;cityId&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;offset&#x27;</span>: i * <span class="number">20</span>,</span><br><span class="line">        <span class="string">&#x27;limit&#x27;</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="string">&#x27;startDay&#x27;</span>: <span class="number">20201212</span>,</span><br><span class="line">        <span class="string">&#x27;endDay&#x27;</span>: <span class="number">20201212</span>,</span><br><span class="line">        <span class="string">&#x27;q&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;sort&#x27;</span>: <span class="string">&#x27;defaults&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;X-FOR-WITH&#x27;</span>: <span class="string">&#x27;y0S49miBphUhlSdxHk0yNx/zQUUPdVFaVHUcE7pp957986DvRcVqn1WFmBoRwkk8sysD+0+jcjaysGC3oiWjgNG1qIsmIorGCBEwXdMKoXyIdf+EQ4DZWwlrv+qY8Yhet4H+/1aKyaQfAXr4MCj//K0IjMPOwYhRX1r9yIHCe3v7W/0jrHmp94an7/7vUBwuzSaMtK70jedmB80BqgYsKA==&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url, headers=headers,  params=data).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    results = json.loads(response)[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;searchresult&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> conn <span class="keyword">in</span> results:</span><br><span class="line">        name = conn[<span class="string">&#x27;name&#x27;</span>]  <span class="comment"># 酒店名字</span></span><br><span class="line">        addr = conn[<span class="string">&#x27;addr&#x27;</span>]  <span class="comment"># 酒店地址</span></span><br><span class="line">        hotelStar = conn[<span class="string">&#x27;hotelStar&#x27;</span>]  <span class="comment"># 酒店类型</span></span><br><span class="line">        originalPrice = conn[<span class="string">&#x27;originalPrice&#x27;</span>]</span><br><span class="line">        comment = conn[<span class="string">&#x27;commentsCountDesc&#x27;</span>]</span><br><span class="line">        score = conn[<span class="string">&#x27;scoreIntro&#x27;</span>]</span><br><span class="line">        lat = conn[<span class="string">&#x27;lat&#x27;</span>]</span><br><span class="line">        lng = conn[<span class="string">&#x27;lng&#x27;</span>]</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">            <span class="string">&#x27;hotelStar&#x27;</span>: hotelStar,</span><br><span class="line">            <span class="string">&#x27;originalPrice&#x27;</span>: originalPrice,</span><br><span class="line">            <span class="string">&#x27;comment&#x27;</span>: comment,</span><br><span class="line">            <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">            <span class="string">&#x27;addr&#x27;</span>: addr,</span><br><span class="line">            <span class="string">&#x27;lat&#x27;</span>: lat,</span><br><span class="line">            <span class="string">&#x27;lng&#x27;</span>: lng</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">print</span>(data)</span><br><span class="line">        data_list.append(data)</span><br><span class="line"></span><br><span class="line">        conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">3306</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;root&#x27;</span>, db=<span class="string">&#x27;spiders2&#x27;</span>, charset=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">        cursor = conn.cursor()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            sql = <span class="string">&#x27;create table if not exists meituan(&#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;name varchar(235) primary key, &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;hotelStar varchar(235), &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;originalPrice varchar(235), &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;comment varchar(235), &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;score varchar(235), &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;addr varchar(235), &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;lat varchar(235), &#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;lng varchar(235)&#x27;</span> \</span><br><span class="line">                  <span class="string">&#x27;)charset utf8&#x27;</span></span><br><span class="line">            cursor.execute(sql)</span><br><span class="line">            table = <span class="string">&#x27;meituan&#x27;</span></span><br><span class="line">            keys = <span class="string">&#x27;,&#x27;</span>.join(data.keys())</span><br><span class="line">            values = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&#x27;%s&#x27;</span>] * <span class="built_in">len</span>(data))</span><br><span class="line">            sql = <span class="string">&#x27;insert into &#123;table&#125;(&#123;keys&#125;) values(&#123;values&#125;)&#x27;</span>.<span class="built_in">format</span>(table=table, keys=keys, values=values)</span><br><span class="line">            cursor.execute(sql, <span class="built_in">tuple</span>(data.values()))</span><br><span class="line">            conn.commit()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            conn.close()</span><br><span class="line"><span class="comment"># with open(&#x27;美团.csv&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;, newline=&#x27;&#x27;) as f:</span></span><br><span class="line"><span class="comment">#     fieldnames = [&#x27;name&#x27;, &#x27;hotelStar&#x27;, &#x27;originalPrice&#x27;, &#x27;comment&#x27;, &#x27;score&#x27;, &#x27;addr&#x27;, &#x27;lat&#x27;, &#x27;lng&#x27;]</span></span><br><span class="line"><span class="comment">#     writer = csv.DictWriter(f, fieldnames=fieldnames)</span></span><br><span class="line"><span class="comment">#     writer.writeheader()</span></span><br><span class="line"><span class="comment">#     writer.writerows(data_list)</span></span><br></pre></td></tr></table></figure>

<p>##9.爬取求是网（xpath)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.qstheory.cn/dukan/qs/2019-01/01/c_1123932149.htm?spm=zm5062-001.0.0.1.OpkwSK&#x27;</span></span><br><span class="line"></span><br><span class="line">html = requests.get(url, headers=headers).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sel = etree.HTML(html)</span><br><span class="line">data_list = []</span><br><span class="line">p_list = sel.xpath(<span class="string">&#x27;//div[@class=&quot;highlight&quot;]/p&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> p_list:</span><br><span class="line">    <span class="comment"># href = p.xpath(&#x27;./strong/a/@href | ./a/@href | ./span/a/@href | ./span/strong/a/@href&#x27;)[0]</span></span><br><span class="line">    href = p.xpath(<span class="string">&#x27;.//@href&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># print(href)</span></span><br><span class="line">    response = requests.get(url=href, headers=headers).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    sel = etree.HTML(response)</span><br><span class="line">    detail_urls = sel.xpath(<span class="string">&#x27;//div[@class=&quot;highlight&quot;]/p/a/@href | //div[@class=&quot;highlight&quot;]/p/strong/a/@href | //div[@class=&quot;highlight&quot;]/p//strong/a/@href&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">        <span class="comment"># print(detail_url)</span></span><br><span class="line">        response = requests.get(url=detail_url, headers=headers).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        sel = etree.HTML(response)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            title = sel.xpath(<span class="string">&#x27;//h1/text()&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;\r\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;\u3000&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            author = sel.xpath(<span class="string">&#x27;/html/body/section/div/div/div/div/span[2]/text()&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;\r\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            time_update = sel.xpath(<span class="string">&#x27;/html/body/section/div/div/div/div/span[3]/text()&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;\r\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            photo = sel.xpath(<span class="string">&#x27;//div[@class=&quot;highlight&quot;]//@src&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(photo) &gt; <span class="number">0</span>:</span><br><span class="line">                time = time_update.split(<span class="string">&#x27; &#x27;</span>)[<span class="number">0</span>].split(<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">                time1 = <span class="string">&#x27;-&#x27;</span>.join(time[<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">                time2 = time[<span class="number">2</span>]</span><br><span class="line">                result = time1 + <span class="string">&#x27;/&#x27;</span> + time2 + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">                photo_url = <span class="string">&#x27;http://www.qstheory.cn/dukan/qs/&#x27;</span> + result + photo[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                photo_url = photo</span><br><span class="line">            content = sel.xpath(<span class="string">&#x27;//div[@class=&quot;highlight&quot;]/p/text() | //div[@class=&quot;highlight&quot;]/p/strong/text()&#x27;</span>)</span><br><span class="line">            content = <span class="string">&#x27;&#x27;</span>.join(content).replace(<span class="string">&#x27;\u3000\u3000&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;\xa0&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;\r\n\r\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span>: title,</span><br><span class="line">                <span class="string">&#x27;author&#x27;</span>: author,</span><br><span class="line">                <span class="string">&#x27;time&#x27;</span>: time_update,</span><br><span class="line">                <span class="string">&#x27;photo_url&#x27;</span>: photo_url,</span><br><span class="line">                <span class="string">&#x27;content&#x27;</span>: content</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">print</span>(data)</span><br><span class="line">            data_list.append(data)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;求是.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    fieldnames = [<span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;photo_url&#x27;</span>, <span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">    writer = csv.DictWriter(f, fieldnames=fieldnames)</span><br><span class="line">    writer.writeheader()</span><br><span class="line">    writer.writerows(data_list)</span><br></pre></td></tr></table></figure>



<h2 id="10爬取豆瓣图书（scrapy"><a href="#10爬取豆瓣图书（scrapy" class="headerlink" title="10爬取豆瓣图书（scrapy)"></a>10爬取豆瓣图书（scrapy)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特点：里外内容合并 meta</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> douban_bookPro.items <span class="keyword">import</span> DoubanBookproItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;book&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        urls = [<span class="string">&#x27;https://book.douban.com/tag/%E6%97%A5%E6%9C%AC%E6%96%87%E5%AD%A6?start=&#123;&#125;&amp;type=T&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span></span><br><span class="line">                <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">980</span>, <span class="number">20</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse)</span><br><span class="line">            <span class="built_in">print</span>(url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># print(response)</span></span><br><span class="line">        detail_links = response.xpath(<span class="string">&#x27;//ul[@class=&quot;subject-list&quot;]/li&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> detail_links:</span><br><span class="line">            link = li.xpath(<span class="string">&#x27;./div/a/@href&#x27;</span>).extract_first()</span><br><span class="line">            img_url = li.xpath(<span class="string">&#x27;./div/a/img/@src&#x27;</span>).extract_first()</span><br><span class="line">            info = li.xpath(<span class="string">&#x27;./div[2]/div[1]/text()&#x27;</span>).extract_first().strip()</span><br><span class="line">            info = <span class="built_in">str</span>(info).split(<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">            author = info[<span class="number">0</span>].rstrip()</span><br><span class="line">            translator = info[<span class="number">1</span>].strip()</span><br><span class="line">            press = info[<span class="number">2</span>].strip()</span><br><span class="line">            price = info[<span class="number">4</span>].strip()</span><br><span class="line">            req = scrapy.Request(url=link, callback=self.detail_parse)</span><br><span class="line">            req.meta[<span class="string">&#x27;link&#x27;</span>] = link</span><br><span class="line">            req.meta[<span class="string">&#x27;img_url&#x27;</span>] = img_url</span><br><span class="line">            req.meta[<span class="string">&#x27;author&#x27;</span>] = author</span><br><span class="line">            req.meta[<span class="string">&#x27;translator&#x27;</span>] = translator</span><br><span class="line">            req.meta[<span class="string">&#x27;press&#x27;</span>] = press</span><br><span class="line">            req.meta[<span class="string">&#x27;price&#x27;</span>] = price</span><br><span class="line">            <span class="keyword">yield</span> req</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        title = response.xpath(<span class="string">&#x27;//h1/span/text()&#x27;</span>).extract_first()</span><br><span class="line">        time = response.xpath(<span class="string">&#x27;//*[@id=&quot;info&quot;]/text()[last()-11]&#x27;</span>).extract_first().strip()</span><br><span class="line">        <span class="keyword">if</span> time <span class="keyword">is</span> <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">            time = response.xpath(<span class="string">&#x27;//*[@id=&quot;info&quot;]/text()[last()-9]&#x27;</span>).extract_first().strip()</span><br><span class="line">        page = response.xpath(<span class="string">&#x27;//*[@id=&quot;info&quot;]/text()[last()-9]&#x27;</span>).extract_first().strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(page.split(<span class="string">&#x27;-&#x27;</span>)) &gt; <span class="number">1</span>:</span><br><span class="line">            page = response.xpath(<span class="string">&#x27;//*[@id=&quot;info&quot;]/text()[last()-7]&#x27;</span>).extract_first().strip()</span><br><span class="line">        binding = response.xpath(<span class="string">&#x27;//*[@id=&quot;info&quot;]/text()[last()-5]&#x27;</span>).extract_first().strip()</span><br><span class="line">        ISBN = response.xpath(<span class="string">&#x27;//*[@id=&quot;info&quot;]/text()[last()-1]&#x27;</span>).extract_first().strip()</span><br><span class="line">        score = response.xpath(<span class="string">&#x27;//*[@id=&quot;interest_sectl&quot;]/div/div[2]/strong/text()&#x27;</span>).extract_first().strip()</span><br><span class="line">        comments = response.xpath(<span class="string">&#x27;//*[@id=&quot;interest_sectl&quot;]/div/div[2]/div/div[2]/span/a/span/text()&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        item = DoubanBookproItem()</span><br><span class="line"></span><br><span class="line">        item[<span class="string">&#x27;ISBN&#x27;</span>] = ISBN</span><br><span class="line">        item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">        item[<span class="string">&#x27;author&#x27;</span>] = response.meta[<span class="string">&#x27;author&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;score&#x27;</span>] = score</span><br><span class="line">        item[<span class="string">&#x27;price&#x27;</span>] = response.meta[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;page&#x27;</span>] = page</span><br><span class="line">        item[<span class="string">&#x27;time&#x27;</span>] = time</span><br><span class="line">        item[<span class="string">&#x27;press&#x27;</span>] = response.meta[<span class="string">&#x27;press&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;translator&#x27;</span>] = response.meta[<span class="string">&#x27;translator&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;binding&#x27;</span>] = binding</span><br><span class="line">        item[<span class="string">&#x27;comments&#x27;</span>] = comments</span><br><span class="line">        item[<span class="string">&#x27;link&#x27;</span>] = response.meta[<span class="string">&#x27;link&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;img_url&#x27;</span>] = response.meta[<span class="string">&#x27;img_url&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line">        <span class="built_in">print</span>(item)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><h2 id="1-requests文档"><a href="#1-requests文档" class="headerlink" title="1.requests文档"></a>1.requests文档</h2><p><a target="_blank" rel="noopener" href="https://requests.readthedocs.io/zh_CN/latest/">requests文档</a></p>
<h2 id="2-scrapy文档"><a href="#2-scrapy文档" class="headerlink" title="2.scrapy文档"></a>2.scrapy文档</h2><p><a target="_blank" rel="noopener" href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html">scrapy文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;qiushi.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.writer(json.dumps(data, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line">    f.writer(json.dumps(data, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">3306</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;root&#x27;</span>, db=<span class="string">&#x27;spiders&#x27;</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line"></span><br><span class="line">keys = <span class="string">&#x27;,&#x27;</span>.join(data.keys())</span><br><span class="line">values = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&#x27;%s&#x27;</span>] * <span class="built_in">len</span>(data))</span><br><span class="line">values = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&#x27;%s&#x27;</span>] * <span class="built_in">len</span>(data))</span><br><span class="line"></span><br><span class="line">sql = <span class="string">&#x27;insert into data(&#123;keys&#125;) values(&#123;values&#125;)&#x27;</span>.<span class="built_in">format</span>(keys=keys, values=values)</span><br><span class="line">cursor.execute(sql, <span class="built_in">tuple</span>(data.values()))</span><br><span class="line">conn.commit()</span><br><span class="line"></span><br><span class="line">keys = <span class="string">&#x27;,&#x27;</span>.join(data.keys())</span><br><span class="line">values = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&#x27;%s&#x27;</span>] * <span class="built_in">len</span>(data))</span><br><span class="line">sql = <span class="string">&#x27;insert into douban(&#123;keys&#125;) values(&#123;values&#125;)&#x27;</span>.<span class="built_in">format</span>(keys=keys, values=values)</span><br><span class="line">cursor.execute(sql, <span class="built_in">tuple</span>(data.values()))</span><br><span class="line">conn.commit()</span><br><span class="line"></span><br><span class="line">conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">3306</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;root&#x27;</span>, db=<span class="string">&#x27;spiders&#x27;</span>, local_infile=<span class="number">1</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">sql = <span class="string">&#x27;create table huang(</span></span><br><span class="line"><span class="string">id int(11),  </span></span><br><span class="line"><span class="string">name varchar(11), </span></span><br><span class="line"><span class="string">sex varchar(11)</span></span><br><span class="line"><span class="string">)charset utf8&#x27;</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line"></span><br><span class="line">sql = <span class="string">&quot;load data local infile &#x27;double.csv&#x27; into table double fields terminated by &#x27;,&#x27;  lines terminated by &#x27;\n&#x27; ignore 1 lines&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>








































    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/04/05/hello-world/" rel="prev" title="Hello World">
      <i class="fa fa-chevron-left"></i> Hello World
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/04/11/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0%E3%80%81%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80"><span class="nav-number">1.</span> <span class="nav-text">第一章、爬虫基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-HTTP-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 HTTP 基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-1-URI-%E5%92%8C-URL"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1.1 URI 和 URL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-2-%E8%B6%85%E6%96%87%E6%9C%AC"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.1.2 超文本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-3-HTTP-%E5%92%8C-HTTPS"><span class="nav-number">1.1.3.</span> <span class="nav-text">1.1.3 HTTP 和 HTTPS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-4-%E8%AF%B7%E6%B1%82"><span class="nav-number">1.1.4.</span> <span class="nav-text">1.1.4 请求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-5-%E5%93%8D%E5%BA%94"><span class="nav-number">1.1.5.</span> <span class="nav-text">1.1.5 响应</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-%E7%88%AC%E8%99%AB%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 爬虫的基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-%E8%83%BD%E6%8A%93%E5%8F%96%E6%80%8E%E6%A0%B7%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.2.2 能抓取怎样的数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-3-JavaScript-%E6%B8%B2%E6%9F%93%E9%A1%B5%E9%9D%A2"><span class="nav-number">1.2.2.</span> <span class="nav-text">1.2.3 JavaScript 渲染页面</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0%E3%80%81%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">第二章、基本库的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E4%BD%BF%E7%94%A8-urllib"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 使用 urllib</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1 发送请求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2-%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2 处理异常</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-3-%E8%A7%A3%E6%9E%90%E9%93%BE%E6%8E%A5"><span class="nav-number">2.1.3.</span> <span class="nav-text">2.1.3 解析链接</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E4%BD%BF%E7%94%A8-requests"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 使用 requests</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.2 高级用法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 正则表达式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-3-search"><span class="nav-number">2.3.1.</span> <span class="nav-text">2.3.3 search()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-4-findall"><span class="nav-number">2.3.2.</span> <span class="nav-text">2.3.4 findall()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-5-sub"><span class="nav-number">2.3.3.</span> <span class="nav-text">2.3.5 sub()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0%E3%80%81%E8%A7%A3%E6%9E%90%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">第三章、解析库的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E4%BD%BF%E7%94%A8-XPath"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 使用 XPath</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-XPath-%E5%B8%B8%E7%94%A8%E4%BD%BF%E7%94%A8%E8%A7%84%E5%88%99"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1 XPath 常用使用规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-3-%E5%AD%90%E8%8A%82%E7%82%B9"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.3 子节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-4-%E5%AD%90%E5%AD%99%E8%8A%82%E7%82%B9"><span class="nav-number">3.1.3.</span> <span class="nav-text">3.1.4 子孙节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-5-%E7%88%B6%E8%8A%82%E7%82%B9"><span class="nav-number">3.1.4.</span> <span class="nav-text">3.1.5 父节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-6-%E5%B1%9E%E6%80%A7%E5%8C%B9%E9%85%8D"><span class="nav-number">3.1.5.</span> <span class="nav-text">3.1.6 属性匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-7-%E6%96%87%E6%9C%AC%E8%8E%B7%E5%8F%96"><span class="nav-number">3.1.6.</span> <span class="nav-text">3.1.7 文本获取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-8%E5%B1%9E%E6%80%A7%E8%8E%B7%E5%8F%96"><span class="nav-number">3.1.7.</span> <span class="nav-text">3.1.8属性获取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-9-%E5%B1%9E%E6%80%A7%E5%A4%9A%E5%80%BC%E5%8C%B9%E9%85%8D"><span class="nav-number">3.1.8.</span> <span class="nav-text">3.1.9 属性多值匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-10-%E5%A4%9A%E5%B1%9E%E6%80%A7%E5%8C%B9%E9%85%8D"><span class="nav-number">3.1.9.</span> <span class="nav-text">3.1.10 多属性匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-11-%E6%8C%89%E5%BA%8F%E9%80%89%E6%8B%A9"><span class="nav-number">3.1.10.</span> <span class="nav-text">3.1.11 按序选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-12-%E8%8A%82%E7%82%B9%E8%BD%B4%E9%80%89%E6%8B%A9"><span class="nav-number">3.1.11.</span> <span class="nav-text">3.1.12 节点轴选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E4%BD%BF%E7%94%A8-Beautiful-Soup"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 使用 Beautiful Soup</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1 基本用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9%E5%99%A8"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2 节点选择器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-%E5%85%B3%E8%81%94%E9%80%89%E6%8B%A9"><span class="nav-number">3.2.3.</span> <span class="nav-text">3.2.3 关联选择</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0%E3%80%81%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><span class="nav-number">4.</span> <span class="nav-text">第四章、数据存储</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 文件存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-TXT-%E6%96%87%E6%9C%AC%E5%AD%98%E5%82%A8"><span class="nav-number">4.1.1.</span> <span class="nav-text">4.1.1 TXT 文本存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-JSON-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-number">4.1.2.</span> <span class="nav-text">4.1.2 JSON 文件存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-CSV-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-number">4.1.3.</span> <span class="nav-text">4.1.3 CSV 文件存储</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 关系型数据库存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-MySQL-%E7%9A%84%E5%AD%98%E5%82%A8"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1 MySQL 的存储</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 非关系型数据库存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-1-MongoDB-%E5%AD%98%E5%82%A8"><span class="nav-number">4.3.1.</span> <span class="nav-text">4.3.1 MongoDB 存储</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0%E3%80%81Ajax%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96"><span class="nav-number">5.</span> <span class="nav-text">第五章、Ajax数据爬取</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0%E3%80%81%E5%8A%A8%E6%80%81%E6%B8%B2%E6%9F%93%E9%A1%B5%E9%9D%A2%E7%88%AC%E5%8F%96"><span class="nav-number">6.</span> <span class="nav-text">第六章、动态渲染页面爬取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-Selenium-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 Selenium 的使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B"><span class="nav-number">7.</span> <span class="nav-text">案例</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BCtop100%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="nav-number">7.1.</span> <span class="nav-text">1. 使用框架爬取猫眼top100的信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE"><span class="nav-number">7.2.</span> <span class="nav-text">2. 爬取豆瓣电影数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E4%BD%BF%E7%94%A8scrapy%E6%A1%86%E6%9E%B6%E7%88%AC%E5%8F%96%E5%B0%8F%E8%AF%B4"><span class="nav-number">7.3.</span> <span class="nav-text">4.使用scrapy框架爬取小说</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E7%88%AC%E5%8F%96%E5%89%8D%E7%A8%8B%E6%97%A0%E5%BF%A7%E6%8B%9B%E8%81%98%E6%95%B0%E6%8D%AE-%E6%AD%A3%E5%88%99"><span class="nav-number">7.4.</span> <span class="nav-text">5.爬取前程无忧招聘数据(正则)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E5%9B%BE%E4%B9%A6%EF%BC%88scrapy"><span class="nav-number">7.5.</span> <span class="nav-text">10爬取豆瓣图书（scrapy)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%87%E6%A1%A3"><span class="nav-number">8.</span> <span class="nav-text">文档</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-requests%E6%96%87%E6%A1%A3"><span class="nav-number">8.1.</span> <span class="nav-text">1.requests文档</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-scrapy%E6%96%87%E6%A1%A3"><span class="nav-number">8.2.</span> <span class="nav-text">2.scrapy文档</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Aunean</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Aunean</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
